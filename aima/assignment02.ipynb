{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Systems\n",
    "\n",
    "## Assignment 2. Programming Intelligent Agents\n",
    "- Eider Diaz A00828174, Campus Monterrey\n",
    "- Carlos Hinojosa A01137566, Campus Monterrey\n",
    "- Miguel Cortes A01270966, Campus Monterrey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE-REFLEX AGENT in FULLY OBSERVABLE ENVIRONMENT #\n",
    "\n",
    "The grid enviroment composed of 6 rows and 6 columns is represented by an \"island\" with different objects placed randomly placed in some cells of the grid. As it was stated in the assigment, the location of all Thing objects in the environment is described by their \\[r,c\\] coordinates, where r represents rows and c is for columns.\n",
    "\n",
    "The environment may contain 5 types of Thing Objects:\n",
    "<ul>\n",
    "    <li>Treasure 1 (T)</li>\n",
    "    <li>Treasure 2 (t)</li>\n",
    "    <li>Disposable Tool (h)</li>\n",
    "    <li>Reusable Tool (H)</li>\n",
    "    <li>Wall (X)</li>\n",
    "</ul>\n",
    "\n",
    "<li><b>percept(self, agent)</b> in this case outputs the contents of the whole grid environment in each step of a run. This means the agent is able to percieve or sense the entirety of the environment at any time. We programmed the percept as a list of objects belonging to the different classes of things that can be placed in the environment. This is convinient because any property of such objects may be accessed from that single percept list (most notably the .location of each object). </li>\n",
    "<li><b>ReflexHunter</b> is the class of our simple-reflex agent. The main characteristic of this type of agent is that it lacks an \"agent.memories\" array to store useful objects it has seen in the environment in previous percepts of previous steps of a run. This type of agent can only output actions based on the current percept of the current step. We theorize that for a fully observable environment this won't make much of a difference since the full environment is always available as a single percept anyways.</li> \n",
    "\n",
    "The simple-reflex agent can move inside the island in four directions “MoveRight”, “MoveLeft”, “MoveUp”, and “MoveDown”. We also included the action \"MoveRandom\" for when an agent can't decide where to move to based on their percepts. This is specially useful to allow a simple reflex agent to be stuck in an unlucky situation. \n",
    "\n",
    "The agent also has actions for grabbing Things as described on the assignment. When certain conditions are met, the agent is able to perform the actions \"greuse\", \"gdispos\", \"gTreasure1\" and \"gTreasure2\" to grab a reusable tool, a disposable tool, a type 1 treasure and a type 2 treasure, respectively.\n",
    "\n",
    "Some auxiliary methods on the program include \"printMatrix\" to show the current state of the Island, \"inInventory\" for the agent to check if they have the required tool to grab a treasure and \"getDirection\", for the agent to decide where to move to, based on the list of percepts. \n",
    "\n",
    "The program that controls how the agent acts upon it's environment is shown in the table below.\n",
    "\n",
    "<table>\n",
    "    <tbody><tr>\n",
    "        <td><b>Percept:</b> </td>\n",
    "        <td>Find tool (H) </td>\n",
    "        <td>Find tool (h)</td>\n",
    "        <td>Find treasure (T)</td>\n",
    "         <td>Find treasure (t)</td>\n",
    "      \n",
    "\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td><b>Action (if not something grabbable in agent´s location move towards an useful object):</b> </td>\n",
    "       <td>pick it</td>\n",
    "       <td>pick it</td>\n",
    "       <td>if has tool (H or h), Open it</td>\n",
    "       <td>if has tool (h), Open it</td>\n",
    "       \n",
    "       \n",
    "   </tr>\n",
    "        \n",
    "</tbody></table>\n",
    "\n",
    "The program is done when it runs out of user-defined iterations or when there are no more Things on the Island, including Treasure1, Treasure2, Disposable Tool and Reusable Tool. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Next cell runs a simple reflex agent program in a fully observable environment. Output depicts the behavior of the agent for all the steps in a 50 iteration run with 3 items of each kind placed randomly in the environment. The starting position of the agent for this run is \\[1, 1\\]<b></b></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Location: [1, 1]\n",
      "Agent Tools: []\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 h T - H - X 1 \n",
      "2 t - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 50\n",
      "Hunter: Grabbed Disposable Tool at [1, 1].\n",
      "Agent Location: [1, 1]\n",
      "Agent Tools: ['h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - T - H - X 1 \n",
      "2 t - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 50\n",
      "Hunter: Moved Right to [1, 2].\n",
      "Agent Location: [1, 2]\n",
      "Agent Tools: ['h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - T - H - X 1 \n",
      "2 t - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 49\n",
      "Hunter: Moved Right to [1, 3].\n",
      "Agent Location: [1, 3]\n",
      "Agent Tools: ['h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - T - H - X 1 \n",
      "2 t - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 48\n",
      "Hunter: Moved Right to [1, 4].\n",
      "Agent Location: [1, 4]\n",
      "Agent Tools: ['h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - T - H - X 1 \n",
      "2 t - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 47\n",
      "Hunter: Grabbed Reusable Tool at [1, 4].\n",
      "Agent Location: [1, 4]\n",
      "Agent Tools: ['h', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - T - - - X 1 \n",
      "2 t - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 47\n",
      "Hunter: Moved Left to [1, 3].\n",
      "Agent Location: [1, 3]\n",
      "Agent Tools: ['h', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - T - - - X 1 \n",
      "2 t - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 46\n",
      "Hunter: Moved Left to [1, 2].\n",
      "Agent Location: [1, 2]\n",
      "Agent Tools: ['h', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - T - - - X 1 \n",
      "2 t - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 45\n",
      "Hunter: Grabbed Treasure1 at [1, 2].\n",
      "Agent Location: [1, 2]\n",
      "Agent Tools: ['h', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 t - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 65\n",
      "Hunter: Moved Left to [1, 1].\n",
      "Agent Location: [1, 1]\n",
      "Agent Tools: ['h', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 t - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 64\n",
      "Hunter: Moved Down to [2, 1].\n",
      "Agent Location: [2, 1]\n",
      "Agent Tools: ['h', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 t - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 63\n",
      "Hunter: Grabbed Treasure2 at [2, 1].\n",
      "Agent Location: [2, 1]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 103\n",
      "Hunter: Moved Right to [2, 2].\n",
      "Agent Location: [2, 2]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 102\n",
      "Hunter: Moved Right to [2, 3].\n",
      "Agent Location: [2, 3]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 101\n",
      "Hunter: Moved Right to [2, 4].\n",
      "Agent Location: [2, 4]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 100\n",
      "Hunter: Moved Right to [2, 5].\n",
      "Agent Location: [2, 5]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - H H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 99\n",
      "Hunter: Grabbed Reusable Tool at [2, 5].\n",
      "Agent Location: [2, 5]\n",
      "Agent Tools: ['H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 99\n",
      "Hunter: Moved Right to [2, 6].\n",
      "Agent Location: [2, 6]\n",
      "Agent Tools: ['H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - H 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 98\n",
      "Hunter: Grabbed Reusable Tool at [2, 6].\n",
      "Agent Location: [2, 6]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 98\n",
      "Hunter: Moved Left to [2, 5].\n",
      "Agent Location: [2, 5]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 97\n",
      "Hunter: Moved Left to [2, 4].\n",
      "Agent Location: [2, 4]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 96\n",
      "Hunter: Moved Left to [2, 3].\n",
      "Agent Location: [2, 3]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 95\n",
      "Hunter: Moved Left to [2, 2].\n",
      "Agent Location: [2, 2]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 94\n",
      "Hunter: Moved Down to [3, 2].\n",
      "Agent Location: [3, 2]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - h - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 93\n",
      "Hunter: Grabbed Disposable Tool at [3, 2].\n",
      "Agent Location: [3, 2]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 93\n",
      "Hunter: Moved Down to [4, 2].\n",
      "Agent Location: [4, 2]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - t T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 92\n",
      "Hunter: Grabbed Treasure2 at [4, 2].\n",
      "Agent Location: [4, 2]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - - T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 132\n",
      "Hunter: Moved Right to [4, 3].\n",
      "Agent Location: [4, 3]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - - T - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 131\n",
      "Hunter: Grabbed Treasure1 at [4, 3].\n",
      "Agent Location: [4, 3]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - - - - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 151\n",
      "Hunter: Moved Down to [5, 3].\n",
      "Agent Location: [5, 3]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - - - - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 150\n",
      "Hunter: Moved Down to [6, 3].\n",
      "Agent Location: [6, 3]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - - - - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - T - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 149\n",
      "Hunter: Grabbed Treasure1 at [6, 3].\n",
      "Agent Location: [6, 3]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - - - - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - - - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 169\n",
      "Hunter: Moved Right to [6, 4].\n",
      "Agent Location: [6, 4]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - - - - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - - - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 168\n",
      "Hunter: Moved Right to [6, 5].\n",
      "Agent Location: [6, 5]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - - - - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - - - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 167\n",
      "Hunter: Moved Right to [6, 6].\n",
      "Agent Location: [6, 6]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - - - - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - - - - h 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 166\n",
      "Hunter: Grabbed Disposable Tool at [6, 6].\n",
      "Agent Location: [6, 6]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - - - - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - - - - - 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 166\n",
      "Hunter: Moved Left to [6, 5].\n",
      "Agent Location: [6, 5]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - - - - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - - - - - 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 165\n",
      "Hunter: Moved Up to [5, 5].\n",
      "Agent Location: [5, 5]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - X 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - X - 3 \n",
      "4 - - - - - - 4 \n",
      "5 - - - - t X 5 \n",
      "6 - - - - - - 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 164\n",
      "Hunter: Grabbed Treasure2 at [5, 5].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents import *\n",
    "from random import *\n",
    "\n",
    "\n",
    "class Treasure1(Thing):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Treasure2(Thing):\n",
    "    pass\n",
    "\n",
    "\n",
    "class DisposTool(Thing):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ReuseTool(Thing):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Island(Environment):\n",
    "    def __init__(self, width=7, height=7):\n",
    "        super(Island, self).__init__()\n",
    "\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        # Sets iteration start and end (no walls).\n",
    "        # self.x_start, self.y_start = (0, 0)\n",
    "        # self.x_end, self.y_end = (self.width, self.height)\n",
    "\n",
    "    def percept(self, agent):\n",
    "        '''prints & return a list of things that are in our agent's location'''\n",
    "        percepts = []\n",
    "        locations = []\n",
    "        # locations = self.getLocations(agent.location)\n",
    "        # TODO: implement 'getLocations function\n",
    "        for i in range(1,7):\n",
    "            for j in range(1,7):\n",
    "                locations.append([i,j])\n",
    "\n",
    "        for location in locations:\n",
    "            things = self.list_things_at(location)\n",
    "            for thing in things:\n",
    "                percepts.append(thing)\n",
    "        return percepts\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        # TODO: check for walls and boundaries\n",
    "        if action == 'moveRandom':\n",
    "            direction = randint(1, 4)\n",
    "            print(\"Hunter: Moved random\")\n",
    "            if direction == 1:\n",
    "                action = 'moveRight'\n",
    "            elif direction == 2:\n",
    "                action = 'moveLeft'\n",
    "            elif direction == 3:\n",
    "                action = 'moveUp'\n",
    "            elif direction == 4:\n",
    "                action = 'moveDown'\n",
    "\n",
    "        if action == 'moveRight':\n",
    "            if agent.location[1] < 6:\n",
    "                walls = self.list_things_at([agent.location[0], agent.location[1]+1], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveRight()\n",
    "                agent.performance -= 1\n",
    "            else:\n",
    "                agent.performance -= 5\n",
    "        elif action == 'moveLeft':\n",
    "            if agent.location[1] > 1:\n",
    "                walls = self.list_things_at([agent.location[0], agent.location[1] - 1], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveLeft()\n",
    "                agent.performance -= 1\n",
    "            else:\n",
    "                agent.performance -= 5\n",
    "        elif action == 'moveUp':\n",
    "            if agent.location[0] > 1:\n",
    "                walls = self.list_things_at([agent.location[0]-1, agent.location[1]], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveUp()\n",
    "                agent.performance -= 1\n",
    "            else:\n",
    "                agent.performance -= 5\n",
    "        elif action == 'moveDown':\n",
    "            if agent.location[0] < 6:\n",
    "                walls = self.list_things_at([agent.location[0] + 1, agent.location[1]], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveDown()\n",
    "                agent.performance -= 1\n",
    "            else:\n",
    "                agent.performance -= 5\n",
    "        elif action == \"Greuse\":\n",
    "            items = self.list_things_at(agent.location, tclass=ReuseTool)\n",
    "            if len(items) != 0:\n",
    "                if agent.greuse(items[0]):  #\n",
    "                    self.delete_thing(items[0])  #\n",
    "                    agent.holding.append('H')\n",
    "        elif action == \"Gdispos\":\n",
    "            agent.gdispos()\n",
    "            items = self.list_things_at(agent.location, tclass=DisposTool)\n",
    "            if len(items) != 0:\n",
    "                if agent.gdispos(items[0]):  #\n",
    "                    self.delete_thing(items[0])  # D\n",
    "                    agent.holding.append('h')\n",
    "        elif action == \"GTreasure1\":\n",
    "            items = self.list_things_at(agent.location, tclass=Treasure1)\n",
    "            if len(items) != 0:\n",
    "                if agent.gTreasure1(items[0]):  # Grab Treasure 1\n",
    "                    # TODO: add to performance\n",
    "                    agent.performance += 20\n",
    "                    self.delete_thing(items[0])  # Delete it from the Island after.\n",
    "        elif action == \"GTreasure2\":\n",
    "            items = self.list_things_at(agent.location, tclass=Treasure2)\n",
    "            if len(items) != 0:\n",
    "                if agent.gTreasure2(items[0]):  # Grab Treasure2\n",
    "                    agent.performance += 40\n",
    "                    agent.holding.remove('h')\n",
    "                    self.delete_thing(items[0])  # Delete it from the Island after.\n",
    "        elif action == \"NoOp\":\n",
    "            pass\n",
    "\n",
    "    def is_done(self):\n",
    "        '''By default, we're done when we can't find a live agent,\n",
    "        but to prevent killing our cute dog, we will or it with when there is no more food or water'''\n",
    "        no_edibles = not any(isinstance(thing, Treasure1) or isinstance(thing, DisposTool) or isinstance(thing, ReuseTool) or isinstance(thing, Treasure2) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n",
    "\n",
    "    def step(self): #AIMA function overriden to access agent status in each step of a run and print the performance\n",
    "        \"\"\"Run the environment for one time step. If the\n",
    "        actions and exogenous changes are independent, this method will\n",
    "        do.  If there are interactions between them, you'll need to\n",
    "        override this method.\"\"\"\n",
    "        if not self.is_done():\n",
    "            actions = []\n",
    "            for agent in self.agents:\n",
    "                if agent.alive:\n",
    "                    actions.append(agent.program(self.percept(agent), agent))\n",
    "                else:\n",
    "                    actions.append(\"\")\n",
    "                \n",
    "            for (agent, action) in zip(self.agents, actions):\n",
    "                self.execute_action(agent, action)\n",
    "            self.exogenous_change()\n",
    "\n",
    "class ReflexHunter(Agent):\n",
    "    def __init__(self, program=None):  # default state of the agent\n",
    "        self.alive = True\n",
    "        self.bump = False\n",
    "        self.type = 'simple_reflex'\n",
    "        self.holding = []\n",
    "        self.performance = 50\n",
    "        if program is None:\n",
    "            def program(percept):\n",
    "                return eval(input('Percept={}; action? '.format(percept)))\n",
    "        # assert isinstance(program, collections.Callable)\n",
    "        self.program = program\n",
    "\n",
    "    def moveRight(self):\n",
    "        self.location[1] += 1\n",
    "        print(\"Hunter: Moved Right to {}.\".format(self.location))\n",
    "\n",
    "    def moveLeft(self):\n",
    "        self.location[1] -= 1\n",
    "        print(\"Hunter: Moved Left to {}.\".format(self.location))\n",
    "\n",
    "    def moveUp(self):\n",
    "        self.location[0] -= 1\n",
    "        print(\"Hunter: Moved Up to {}.\".format(self.location))\n",
    "\n",
    "    def moveDown(self):\n",
    "        self.location[0] += 1\n",
    "        print(\"Hunter: Moved Down to {}.\".format(self.location))\n",
    "\n",
    "    def greuse(self, thing):\n",
    "        '''returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, ReuseTool):\n",
    "            print(\"Hunter: Grabbed Reusable Tool at {}.\".format(self.location))\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def gdispos(self, thing = None):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, DisposTool):\n",
    "            print(\"Hunter: Grabbed Disposable Tool at {}.\".format(self.location))\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def gTreasure1(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Treasure1):\n",
    "            print(\"Hunter: Grabbed Treasure1 at {}.\".format(self.location))\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def gTreasure2(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Treasure2):\n",
    "            print(\"Hunter: Grabbed Treasure2 at {}.\".format(self.location))\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "def program(percepts, agent):\n",
    "    '''Returns an action based on it's percepts'''\n",
    "    print(\"Agent Location: \" + str(agent.location))\n",
    "    print(\"Agent Tools: \" + str(agent.holding))\n",
    "    printMatrix(percepts)\n",
    "    print(\"\")\n",
    "    print(\"Agent performance: \" + str(agent.performance))\n",
    "    if agent.type == 'modelbased':\n",
    "        print(\"INTERNAL STATE:\")\n",
    "        print(agent.seen)\n",
    "    actionTaken = False\n",
    "    for p in percepts:\n",
    "        # Grab actions for when agent is in same location\n",
    "        if actionTaken:\n",
    "            break\n",
    "        in_location = agent.location == p.location\n",
    "        if isinstance(p, Treasure1) and inInventory('H', agent):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'GTreasure1'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "        elif isinstance(p, Treasure2) and inInventory('h', agent):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'GTreasure2'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "        elif isinstance(p, DisposTool):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'Gdispos'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "        elif isinstance(p, ReuseTool):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'Greuse'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "\n",
    "    if not actionTaken:\n",
    "        return 'moveRandom'\n",
    "\n",
    "def printMatrix(percepts):\n",
    "    for i in range(0, 8):\n",
    "        print(\"\")\n",
    "        for j in range(0, 8):\n",
    "            if (i == 0 and j == 0) or (i == 7 and j == 7):\n",
    "                print(\"\\\\\", end=\" \")\n",
    "\n",
    "            elif (i == 0 and j == 7) or (i == 7 and j == 0):\n",
    "                print(\"/\", end=\" \")\n",
    "\n",
    "            elif (i == 0 or i == 7):\n",
    "                print(\"\".join(str(j)), end=\" \")\n",
    "\n",
    "            elif (j == 0 or j == 7):\n",
    "                print(\"\".join(str(i)), end=\" \")\n",
    "\n",
    "            else:\n",
    "                #Check percepts, print if matches location\n",
    "                printed = False\n",
    "                for p in percepts:\n",
    "                    if p.location == [i,j]:\n",
    "                        if isinstance(p, Treasure1):\n",
    "                            printed = True\n",
    "                            print(\"T\", end=\" \")\n",
    "                        elif isinstance(p, Treasure2):\n",
    "                            printed = True\n",
    "                            print(\"t\", end=\" \")\n",
    "                        elif isinstance(p, DisposTool):\n",
    "                            printed = True\n",
    "                            print(\"h\", end=\" \")\n",
    "                        elif isinstance(p, ReuseTool):\n",
    "                            printed = True\n",
    "                            print(\"H\", end=\" \")\n",
    "                        elif isinstance(p, Wall):\n",
    "                            printed = True\n",
    "                            print(\"X\", end=\" \")\n",
    "                if not printed:\n",
    "                    print(\"-\", end=\" \")\n",
    "\n",
    "\n",
    "def inInventory(tool, agent):\n",
    "    for hold in agent.holding:\n",
    "        if hold == tool:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def getDirection(origin, goal):\n",
    "    if origin[1] < goal[1]:\n",
    "        return 'moveRight'\n",
    "    elif origin[1] > goal[1]:\n",
    "        return 'moveLeft'\n",
    "    elif origin[0] > goal[0]:\n",
    "        return 'moveUp'\n",
    "    else:\n",
    "        return 'moveDown'\n",
    "    \n",
    "def main(start = [1, 1]):\n",
    "    '''Run the simple reflex hunter in the partial treasure island environment'''\n",
    "    island = Island()\n",
    "    charlie = ReflexHunter(program)\n",
    "\n",
    "    #Create 3 objects of each kind to place on the environment\n",
    "    treasure1A = Treasure1()\n",
    "    treasure1B = Treasure1()\n",
    "    treasure1C = Treasure1()\n",
    "    treasure2A = Treasure2()\n",
    "    treasure2B = Treasure2()\n",
    "    treasure2C = Treasure2()\n",
    "    dispos1 = DisposTool()\n",
    "    dispos2 = DisposTool()\n",
    "    dispos3 = DisposTool()\n",
    "    reusable1 = ReuseTool()\n",
    "    reusable2 = ReuseTool()\n",
    "    reusable3 = ReuseTool()\n",
    "    wall = Wall()\n",
    "    wall2 = Wall()\n",
    "    wall3 = Wall()\n",
    "    \n",
    "    #add things randomly preventing placing more than one item in a single cell in the environment\n",
    "    xy = [[1, 1],[1, 2],[1, 3],[1, 4],[1, 5],[1, 6],\n",
    "          [2, 1],[2, 2],[2, 3],[2, 4],[2, 5],[2, 6],\n",
    "          [3, 1],[3, 2],[3, 3],[3, 4],[3, 5],[3, 6],\n",
    "          [4, 1],[4, 2],[4, 3],[4, 4],[4, 5],[4, 6],\n",
    "          [5, 1],[5, 2],[5, 3],[5, 4],[5, 5],[5, 6],\n",
    "          [6, 1],[6, 2],[6, 3],[6, 4],[6, 5],[6, 6]]\n",
    "\n",
    "    island.add_thing(charlie, start)\n",
    "    charlie.performance = 50 #prevents AIMA from resetting the performance to 0 when adding the agent to the environment\n",
    "\n",
    "    island.add_thing(treasure1A, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(treasure1B, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(treasure1C, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(reusable1, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(reusable2, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(reusable3, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(treasure2A, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(treasure2B, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(treasure2C, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(dispos1, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(dispos2, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(dispos3, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(wall, xy.pop(randint(0, len(xy)) - 1))\n",
    "    island.add_thing(wall2, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(wall3, xy.pop(randint(0, len(xy) - 1)))\n",
    "\n",
    "    island.run(50) #run the program for 50 iterations\n",
    "    return charlie.performance #for studying several runs\n",
    "                                          \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell executes 500 runs of 50 iterations each of the previous agent and environment. The average agent performance of the runs is computed (takes less than a minute to run but its not inmediate please be patient). The agent location for these runs is also randomized like the location of the objects. Stdout is supressed to avoid excessive printing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "total_performance = 0\n",
    "for i in range (1, 500):\n",
    "    run_result = main(start=[randint(1, 6), randint(1, 6)]);\n",
    "    total_performance += run_result\n",
    "average_performance = total_performance / 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell prints the average agent performance from the last experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.782"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE-REFLEX AGENT in PARTIALLY OBSERVABLE ENVIRONMENT #\n",
    "\n",
    "This model works exactly the same as the last one except for one difference: the percept on each step of a run is not the whole environment anymore. In the percept function of the environment there is a getLocations function which retrieves the location of the cells adjacent to the agent's current position (up to 8 when its not in the border of the grid). These locations then are used to construct the array of percepts which is now limited to adjacent cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Next cell runs a simple reflex agent program in a partially observable environment. Output depicts the behavior of the agent for all the steps in a 50 iteration run with 3 items of each kind placed randomly in the environment. The starting position of the agent for this run is \\[1, 1\\]<b></b></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMPLE REFLEX AGENT in PARTIALLY OBSERVABLE ENVIRONMENT\n",
      "<STARTING>\n",
      "Agent location: [1, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  h  h  -  -  3  \n",
      "4  H  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "Agent performance: 50\n",
      "\n",
      "<STEP1>\n",
      "PERCEPT\n",
      "Agent location: [1, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  ?  ?  ?  ?  1  \n",
      "2  -  X  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 49\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  h  h  -  -  3  \n",
      "4  H  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP2>\n",
      "PERCEPT\n",
      "Agent location: [2, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  ?  ?  ?  ?  1  \n",
      "2  -  X  ?  ?  ?  ?  2  \n",
      "3  -  X  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 48\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  h  h  -  -  3  \n",
      "4  H  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP3>\n",
      "PERCEPT\n",
      "Agent location: [3, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  ?  ?  1  \n",
      "2  -  X  ?  ?  ?  ?  2  \n",
      "3  -  X  ?  ?  ?  ?  3  \n",
      "4  H  -  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 47\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [4, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  h  h  -  -  3  \n",
      "4  H  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP4>\n",
      "PERCEPT\n",
      "Agent location: [4, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  ?  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  -  X  ?  ?  ?  ?  3  \n",
      "4  H  -  ?  ?  ?  ?  4  \n",
      "5  -  -  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Greuse\n",
      "NEW AGENT'S PERFORMANCE: 46\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [4, 1]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  h  h  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP5>\n",
      "PERCEPT\n",
      "Agent location: [4, 1]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  ?  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  -  X  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  -  -  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 41\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [4, 1]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  h  h  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP6>\n",
      "PERCEPT\n",
      "Agent location: [4, 1]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  ?  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  -  X  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  -  -  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 40\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [4, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  h  h  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP7>\n",
      "PERCEPT\n",
      "Agent location: [4, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  ?  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  -  X  h  ?  ?  ?  3  \n",
      "4  -  -  t  ?  ?  ?  4  \n",
      "5  -  -  -  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 39\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [4, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  h  h  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP8>\n",
      "PERCEPT\n",
      "Agent location: [4, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  ?  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  X  h  h  ?  ?  3  \n",
      "4  ?  -  t  -  ?  ?  4  \n",
      "5  ?  -  -  -  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 38\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  h  h  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP9>\n",
      "PERCEPT\n",
      "Agent location: [3, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  ?  ?  1  \n",
      "2  ?  X  -  X  ?  ?  2  \n",
      "3  ?  X  h  h  ?  ?  3  \n",
      "4  ?  -  t  -  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Gdispos\n",
      "NEW AGENT'S PERFORMANCE: 36\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 3]\n",
      "Agent tools: ['H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  -  h  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP10>\n",
      "PERCEPT\n",
      "Agent location: [3, 3]\n",
      "Agent tools: ['H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  ?  ?  1  \n",
      "2  ?  X  -  X  ?  ?  2  \n",
      "3  ?  X  -  h  ?  ?  3  \n",
      "4  ?  -  t  -  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 35\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 4]\n",
      "Agent tools: ['H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  -  h  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP11>\n",
      "PERCEPT\n",
      "Agent location: [3, 4]\n",
      "Agent tools: ['H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  ?  ?  1  \n",
      "2  ?  ?  -  X  H  ?  2  \n",
      "3  ?  ?  -  h  -  ?  3  \n",
      "4  ?  ?  t  -  -  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Gdispos\n",
      "NEW AGENT'S PERFORMANCE: 33\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 4]\n",
      "Agent tools: ['H', 'h', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP12>\n",
      "PERCEPT\n",
      "Agent location: [3, 4]\n",
      "Agent tools: ['H', 'h', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  ?  ?  1  \n",
      "2  ?  ?  -  X  H  ?  2  \n",
      "3  ?  ?  -  -  -  ?  3  \n",
      "4  ?  ?  t  -  -  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 32\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 5]\n",
      "Agent tools: ['H', 'h', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP13>\n",
      "PERCEPT\n",
      "Agent location: [3, 5]\n",
      "Agent tools: ['H', 'h', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  ?  ?  1  \n",
      "2  ?  ?  ?  X  H  h  2  \n",
      "3  ?  ?  ?  -  -  -  3  \n",
      "4  ?  ?  ?  -  -  t  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 31\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 5]\n",
      "Agent tools: ['H', 'h', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  H  h  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP14>\n",
      "PERCEPT\n",
      "Agent location: [2, 5]\n",
      "Agent tools: ['H', 'h', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  t  -  T  1  \n",
      "2  ?  ?  ?  X  H  h  2  \n",
      "3  ?  ?  ?  -  -  -  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Greuse\n",
      "NEW AGENT'S PERFORMANCE: 30\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 5]\n",
      "Agent tools: ['H', 'h', 'h', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  -  h  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP15>\n",
      "PERCEPT\n",
      "Agent location: [2, 5]\n",
      "Agent tools: ['H', 'h', 'h', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  t  -  T  1  \n",
      "2  ?  ?  ?  X  -  h  2  \n",
      "3  ?  ?  ?  -  -  -  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 29\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  -  h  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP16>\n",
      "PERCEPT\n",
      "Agent location: [2, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  T  1  \n",
      "2  ?  ?  ?  ?  -  h  2  \n",
      "3  ?  ?  ?  ?  -  -  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Gdispos\n",
      "NEW AGENT'S PERFORMANCE: 27\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP17>\n",
      "PERCEPT\n",
      "Agent location: [2, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  T  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  -  -  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 26\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  T  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP18>\n",
      "PERCEPT\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  T  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: GTreas1\n",
      "NEW AGENT'S PERFORMANCE: 46\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP19>\n",
      "PERCEPT\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  -  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 41\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP20>\n",
      "PERCEPT\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  -  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 36\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP21>\n",
      "PERCEPT\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  -  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 35\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP22>\n",
      "PERCEPT\n",
      "Agent location: [2, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  -  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  -  -  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 34\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP23>\n",
      "PERCEPT\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  -  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 33\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP24>\n",
      "PERCEPT\n",
      "Agent location: [2, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  -  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  -  -  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 32\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP25>\n",
      "PERCEPT\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  -  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 27\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP26>\n",
      "PERCEPT\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  -  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 26\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 5]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP27>\n",
      "PERCEPT\n",
      "Agent location: [1, 5]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  t  -  -  1  \n",
      "2  ?  ?  ?  X  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 25\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  t  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP28>\n",
      "PERCEPT\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  -  t  -  ?  1  \n",
      "2  ?  ?  -  X  -  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: GTreas2\n",
      "NEW AGENT'S PERFORMANCE: 65\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP29>\n",
      "PERCEPT\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  -  -  -  ?  1  \n",
      "2  ?  ?  -  X  -  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 64\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 5]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP30>\n",
      "PERCEPT\n",
      "Agent location: [1, 5]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  -  -  -  1  \n",
      "2  ?  ?  ?  X  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 63\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP31>\n",
      "PERCEPT\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  -  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 58\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP32>\n",
      "PERCEPT\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  -  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 53\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP33>\n",
      "PERCEPT\n",
      "Agent location: [1, 6]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  -  -  1  \n",
      "2  ?  ?  ?  ?  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 52\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 5]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP34>\n",
      "PERCEPT\n",
      "Agent location: [1, 5]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  -  -  -  1  \n",
      "2  ?  ?  ?  X  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 51\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 5]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP35>\n",
      "PERCEPT\n",
      "Agent location: [2, 5]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  -  -  -  1  \n",
      "2  ?  ?  ?  X  -  -  2  \n",
      "3  ?  ?  ?  -  -  -  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 50\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 5]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP36>\n",
      "PERCEPT\n",
      "Agent location: [1, 5]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  -  -  -  1  \n",
      "2  ?  ?  ?  X  -  -  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 49\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP37>\n",
      "PERCEPT\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  -  -  -  ?  1  \n",
      "2  ?  ?  -  X  -  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 48\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 3]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP38>\n",
      "PERCEPT\n",
      "Agent location: [1, 3]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  T  -  -  ?  ?  1  \n",
      "2  ?  X  -  X  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 47\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 2]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP39>\n",
      "PERCEPT\n",
      "Agent location: [1, 2]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  T  -  ?  ?  ?  1  \n",
      "2  -  X  -  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: GTreas1\n",
      "NEW AGENT'S PERFORMANCE: 67\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 2]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP40>\n",
      "PERCEPT\n",
      "Agent location: [1, 2]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  ?  ?  ?  1  \n",
      "2  -  X  -  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 66\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 3]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP41>\n",
      "PERCEPT\n",
      "Agent location: [1, 3]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  -  -  -  ?  ?  1  \n",
      "2  ?  X  -  X  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 65\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP42>\n",
      "PERCEPT\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  -  -  -  ?  1  \n",
      "2  ?  ?  -  X  -  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 60\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP43>\n",
      "PERCEPT\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  -  -  -  ?  1  \n",
      "2  ?  ?  -  X  -  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: NoOp saw a wall\n",
      "NEW AGENT'S PERFORMANCE: 60\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP44>\n",
      "PERCEPT\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  -  -  -  ?  1  \n",
      "2  ?  ?  -  X  -  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: NoOp saw a wall\n",
      "NEW AGENT'S PERFORMANCE: 60\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP45>\n",
      "PERCEPT\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  -  -  -  ?  1  \n",
      "2  ?  ?  -  X  -  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 55\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP46>\n",
      "PERCEPT\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  -  -  -  ?  1  \n",
      "2  ?  ?  -  X  -  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 54\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 3]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP47>\n",
      "PERCEPT\n",
      "Agent location: [1, 3]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  -  -  -  ?  ?  1  \n",
      "2  ?  X  -  X  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 49\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 3]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP48>\n",
      "PERCEPT\n",
      "Agent location: [1, 3]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  -  -  -  ?  ?  1  \n",
      "2  ?  X  -  X  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 44\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 3]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP49>\n",
      "PERCEPT\n",
      "Agent location: [1, 3]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  -  -  -  ?  ?  1  \n",
      "2  ?  X  -  X  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 43\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP50>\n",
      "PERCEPT\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  -  -  -  ?  1  \n",
      "2  ?  ?  -  X  -  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 38\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H', 'h', 'H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  -  -  1  \n",
      "2  -  X  -  X  -  -  2  \n",
      "3  -  X  -  -  -  -  3  \n",
      "4  -  -  t  -  -  t  4  \n",
      "5  -  -  -  -  T  -  5  \n",
      "6  -  -  -  H  -  -  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "FINAL AGENT's PERFORMANCE: 38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the libraries used for constructing this agent and environment\n",
    "from agents import *\n",
    "from random import *\n",
    "import numpy as np\n",
    "\n",
    "#Create the classes of the objects placed in the enviroments\n",
    "class Treasure1(Thing):\n",
    "    pass\n",
    "\n",
    "class Treasure2(Thing):\n",
    "    pass\n",
    "\n",
    "class DisposTool(Thing):\n",
    "    pass\n",
    "\n",
    "class ReuseTool(Thing):\n",
    "    pass\n",
    "\n",
    "class Wall(Thing):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "#Create a partially observable class for the environment\n",
    "class PartialIsland(Environment):\n",
    "    def __init__(self, width=7, height=7): #Default shape of the environment is square 7x7\n",
    "        super(PartialIsland, self).__init__()\n",
    "\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "    \n",
    "    def percept(self, agent): #returns a list of objects that the given agent can sense\n",
    "        self.percepts = []\n",
    "        \n",
    "        locations = self.getPartialLocations(agent.location) #coordinates used to fetch the objects perceivable by the agent\n",
    "\n",
    "        for locus in locations:\n",
    "            things = self.list_things_at(locus)\n",
    "            for thing in things:\n",
    "                self.percepts.append(thing)\n",
    "        return self.percepts\n",
    "    \n",
    "    def getPartialLocations(self, agent_locus): #returns a list of coordinates of the cells adjacent to the current agent's position\n",
    "        here = [agent_locus[0], agent_locus[1]]\n",
    "        up = [agent_locus[0] - 1, agent_locus[1]]\n",
    "        upright = [agent_locus[0] - 1, agent_locus[1] + 1]\n",
    "        right = [agent_locus[0], agent_locus[1] + 1]\n",
    "        downright = [agent_locus[0] + 1, agent_locus[1] + 1]\n",
    "        down = [agent_locus[0] + 1, agent_locus[1]]\n",
    "        downleft = [agent_locus[0] + 1, agent_locus[1] - 1]\n",
    "        left = [agent_locus[0], agent_locus[1] - 1]\n",
    "        upleft = [agent_locus[0] - 1, agent_locus[1] - 1]\n",
    "        \n",
    "        locations = [here, up, upright, right, downright, down, downleft, left, upleft]\n",
    "        return locations\n",
    "    \n",
    "            \n",
    "    def execute_action(self, agent, action): #this function is called when running the environment after the agent's program returns an action\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        \n",
    "        if action == 'moveRandom':\n",
    "            direction = randint(1, 4)\n",
    "            print(\"SELECTED ACTION: Random\")\n",
    "            if direction == 1:\n",
    "                action = 'moveRight'\n",
    "            elif direction == 2:\n",
    "                action = 'moveLeft'\n",
    "            elif direction == 3:\n",
    "                action = 'moveUp'\n",
    "            elif direction == 4:\n",
    "                action = 'moveDown'\n",
    "                '''This module handles the case when the agent percieved only walls or empty spaces in the cells adjacent to it. The agent in this\n",
    "                case decides to prepare a random movement action. Another case of this module being called is when the agent is able to percieve\n",
    "                a treasure but it does not hold a tool that can unlock it. This scenario is effectively the same as ignoring the treasure.'''\n",
    "\n",
    "        if action == 'moveRight':\n",
    "            if agent.location[1] < 6:\n",
    "                walls = self.list_things_at([agent.location[0], agent.location[1]+1], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveRight()\n",
    "                    print(\"SELECTED ACTION: Right\")\n",
    "                else:\n",
    "                    agent.NoOp()\n",
    "            else:\n",
    "                print(\"SELECTED ACTION: canceled, tried to move out of bounds\")\n",
    "                agent.performance -= 5\n",
    "                '''This module handles the case when the agent decided to move right. First a check is performed to see if the agent decided to move out\n",
    "                of bounds, in this case the agent's location does not change in the environment and 5 points are deducted from the performance for the\n",
    "                agent's intent. If the move was in-bounds then it is checked wether or not the destination cell contains a wall; if this is the case the\n",
    "                agent's decision to move is changed to standing still, otherwise the agent moves and its location is updated in the env successfully'''\n",
    "                        \n",
    "        elif action == 'moveLeft':\n",
    "            if agent.location[1] > 1:\n",
    "                walls = self.list_things_at([agent.location[0], agent.location[1]-1], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveLeft()\n",
    "                    print(\"SELECTED ACTION: Left\")\n",
    "                else:\n",
    "                    agent.NoOp()\n",
    "            else:\n",
    "                print(\"SELECTED ACTION: canceled, tried to move out of bounds\")\n",
    "                agent.performance -= 5\n",
    "                '''This module handles the case when the agent decided to move left. It follows the same logic as the previous module'''\n",
    "        \n",
    "        elif action == 'moveUp':\n",
    "            if agent.location[0] > 1:\n",
    "                walls = self.list_things_at([agent.location[0] - 1, agent.location[1]], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveUp()\n",
    "                    print(\"SELECTED ACTION: Up\")\n",
    "                else:\n",
    "                    agent.NoOp()\n",
    "            else:\n",
    "                print(\"SELECTED ACTION: canceled, tried to move out of bounds\")\n",
    "                agent.performance -= 5\n",
    "                '''This module handles the case when the agent decided to move up. It follows the same logic as the previous module'''\n",
    "                \n",
    "        elif action == 'moveDown':\n",
    "            if agent.location[0] < 6:\n",
    "                walls = self.list_things_at([agent.location[0] + 1, agent.location[1]], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveDown()\n",
    "                    print(\"SELECTED ACTION: Down\")\n",
    "                else:\n",
    "                    agent.NoOp()\n",
    "            else:\n",
    "                print(\"SELECTED ACTION: canceled, tried to move out of bounds\")\n",
    "                agent.performance -= 5\n",
    "                '''This module handles the case when the agent decided to move down. It follows the same logic as the previous module'''\n",
    "                \n",
    "        elif action == \"Greuse\":\n",
    "            items = self.list_things_at(agent.location, tclass=ReuseTool)\n",
    "            if len(items) != 0:\n",
    "                if agent.greuse(items[0]):\n",
    "                    self.delete_thing(items[0])\n",
    "                    self.matrix[items[0].location[0]][items[0].location[1]] = '-'\n",
    "                    '''This module handles the case when the agent decides to grab a reusable tool. First a confirmation that a reusable tool object is\n",
    "                    indeed in the current agent's location is performed. Upon success in the check, the agent picks up the tool, then it is deleted from\n",
    "                    the env (internally from the array of things in the env) and finally the graphic representation of the env is modified accordingly'''\n",
    "        \n",
    "        elif action == \"Gdispos\":\n",
    "            agent.gdispos()\n",
    "            items = self.list_things_at(agent.location, tclass=DisposTool)\n",
    "            if len(items) != 0:\n",
    "                if agent.gdispos(items[0]):\n",
    "                    self.delete_thing(items[0])\n",
    "                    self.matrix[items[0].location[0]][items[0].location[1]] = '-'\n",
    "                    '''This module handles the case when the agent decides to grab a disposable tool. It follows the same logic as the previous module'''\n",
    "        \n",
    "        elif action == \"GTreasure1\":\n",
    "            items = self.list_things_at(agent.location, tclass=Treasure1)\n",
    "            if len(items) != 0:\n",
    "                if agent.gTreasure1(items[0]): \n",
    "                    self.delete_thing(items[0])\n",
    "                    self.matrix[items[0].location[0]][items[0].location[1]] = '-'\n",
    "                    '''This module handles the case when the agent decides to grab a type 1 treasure. It follows the same logic as the previous module'''\n",
    "        \n",
    "        elif action == \"GTreasure2\":\n",
    "            items = self.list_things_at(agent.location, tclass=Treasure2)\n",
    "            if len(items) != 0:\n",
    "                if agent.gTreasure2(items[0]):\n",
    "                    self.delete_thing(items[0])\n",
    "                    self.matrix[items[0].location[0]][items[0].location[1]] = '-'\n",
    "                    '''This module handles the case when the agent decides to grab a type 2 treasure. It follows the same logic as the previous module'''\n",
    "        \n",
    "        elif action == \"NoOp\":\n",
    "            pass\n",
    "        \n",
    "        #Report the modified environment along with agent status\n",
    "        print(\"NEW AGENT'S PERFORMANCE: \" + str(agent.performance))\n",
    "        print(\"NEW ENVIRONMENT STATE\")\n",
    "        print(\"Agent location: \" + str(agent.location))\n",
    "        print(\"Agent tools: \" + str(agent.holding))\n",
    "        print('\\n'.join([''.join(['{:3}'.format(item) for item in row]) \n",
    "              for row in self.matrix]))\n",
    "    \n",
    "    def run(self, steps=50): #AIMA function overriden to create a graphical representation of the environment and report starting status\n",
    "        \"Run the Environment for given number of time steps.\"\n",
    "        print(\"SIMPLE REFLEX AGENT in PARTIALLY OBSERVABLE ENVIRONMENT\")\n",
    "        print(\"<STARTING>\")\n",
    "        print(\"Agent location: \" + str(self.things[0].location))\n",
    "        print(\"Agent tools: \" + str(self.things[0].holding))\n",
    "        \n",
    "        self.matrix = templateEnv(size = 6) #create an empty matrix for representing the environment graphically\n",
    "        self.matrix = fillEnv(self.matrix, self.things) #fill the matrix with objects in the environment\n",
    "        print(\"Agent performance: \" + str(self.things[0].performance))\n",
    "        \n",
    "        for step in range(steps):\n",
    "            if self.is_done():\n",
    "                print(\"\\nFINAL AGENT's PERFORMANCE: \" + str(self.things[0].performance)) #print the performance after last step of the run\n",
    "                return\n",
    "            print(\"\\n<STEP\" + str(step + 1) + \">\") #print step number starting from 1\n",
    "            self.step()\n",
    "        \n",
    "        print(\"\\nFINAL AGENT's PERFORMANCE: \" + str(self.things[0].performance)) #print the performance after last step of the run\n",
    "        \n",
    "    def step(self): #AIMA function overriden to access agent status in each step of a run and print the performance\n",
    "        \"\"\"Run the environment for one time step. If the\n",
    "        actions and exogenous changes are independent, this method will\n",
    "        do.  If there are interactions between them, you'll need to\n",
    "        override this method.\"\"\"\n",
    "        if not self.is_done():\n",
    "            actions = []\n",
    "            for agent in self.agents:\n",
    "                if agent.alive:\n",
    "                    actions.append(agent.program(agent, self.percept(agent)))\n",
    "                else:\n",
    "                    actions.append(\"\")\n",
    "                \n",
    "            #Print a graphical matrix representation of what the agent was percieving along with its status at that moment\n",
    "            print(\"PERCEPT\")\n",
    "            print(\"Agent location: \" + str(agent.location))\n",
    "            print(\"Agent tools: \" + str(agent.holding))\n",
    "            percept_repr = templateEnv(size = 6)\n",
    "            percept_repr = getUnknownsReflex(percept_repr, agent.location)\n",
    "            fillEnv(percept_repr, self.percepts)\n",
    "                \n",
    "            for (agent, action) in zip(self.agents, actions):\n",
    "                self.execute_action(agent, action)\n",
    "            self.exogenous_change()\n",
    "            \n",
    "    def is_done(self): #AIMA function overriden to terminate the run if there are no objects of interest left in the environment\n",
    "        no_edibles = not any(isinstance(thing, Treasure1) or isinstance(thing, DisposTool) or isinstance(thing, ReuseTool) or isinstance(thing, Treasure2) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n",
    "    \n",
    "    \n",
    "#Create a simple reflex agent for use in an island environment\n",
    "class ReflexHunter(Agent):\n",
    "    def __init__(self, program=None): #default state of the agent\n",
    "        self.alive = True\n",
    "        self.bump = False\n",
    "        self.holding = []\n",
    "        self.performance = 50\n",
    "        if program is None:\n",
    "            def program(percept):\n",
    "                return eval(input('Percept={}; action? ' .format(percept)))\n",
    "        assert isinstance(program, collections.Callable)\n",
    "        self.program = program\n",
    "        \n",
    "    #The following 4 methods are actions that the agent executes when it wants to move. Which move of the four is called depends on the calculations\n",
    "    #made in the reflexProgram() function and on wether or not the action is valid in the current state of the environment as seen in execute_action()\n",
    "    #in the environment's methods. Performance is reduced by one point in all cases\n",
    "    def moveRight(self):\n",
    "        self.performance -= 1\n",
    "        self.location[1] += 1\n",
    "\n",
    "    def moveLeft(self):\n",
    "        self.performance -= 1\n",
    "        self.location[1] -= 1\n",
    "\n",
    "    def moveUp(self):\n",
    "        self.performance -= 1\n",
    "        self.location[0] -= 1\n",
    "\n",
    "    def moveDown(self):\n",
    "        self.performance -= 1\n",
    "        self.location[0] += 1\n",
    "\n",
    "    #The following 4 functions are actions that the agent executes when it wants to grab something. They operate in the a similar fashion as the\n",
    "    #movement methods except that the agent's inventory is also manipulated\n",
    "    def greuse(self, thing):\n",
    "        self.performance -= 1\n",
    "        if isinstance(thing, ReuseTool):\n",
    "            print(\"SELECTED ACTION: Greuse\")\n",
    "            self.holding.append('H')\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def gdispos(self, thing = None):\n",
    "        self.performance -= 1\n",
    "        if isinstance(thing, DisposTool):\n",
    "            print(\"SELECTED ACTION: Gdispos\")\n",
    "            self.holding.append('h')\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def gTreasure1(self, thing):\n",
    "        if isinstance(thing, Treasure1):\n",
    "            print(\"SELECTED ACTION: GTreas1\")\n",
    "            self.performance += 20\n",
    "            if 'H' in self.holding == False:\n",
    "                self.holding.remove('h')\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def gTreasure2(self, thing):\n",
    "        if isinstance(thing, Treasure2):\n",
    "            print(\"SELECTED ACTION: GTreas2\")\n",
    "            self.performance += 40\n",
    "            self.holding.remove('h')\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    #This action is performed when there is a wall at a cell where the agent wants to move to. Mantains the agent's location for the current step\n",
    "    def NoOp(self):\n",
    "        print(\"SELECTED ACTION: NoOp saw a wall\")\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def reflexProgram(agent, percepts):\n",
    "    '''returns a string dictating the action to be performed by the agent and ultimately what needs to be modified in environment'''\n",
    "    actionTaken = False\n",
    "    \n",
    "    for p in percepts:\n",
    "        if actionTaken:\n",
    "            break\n",
    "            \n",
    "        in_location = agent.location == p.location #used to check the agent's current location for a grabable object\n",
    "        \n",
    "        if isinstance(p, Treasure1) and ('h' in agent.holding or 'H' in agent.holding):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'GTreasure1'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "                '''This module handles when the agent is able to sense a type 1 treasure. First check if the agent has a any kind of tool to grab the\n",
    "                treasure: if not then let this iteration of the loop pass because there is no way to obtain the treasure right now (a new percept is\n",
    "                checked in the next iteration), if yes check if the treasure is at the same place as the agent, if not move towards it by calling the\n",
    "                getDirection() function, if yes output the grab action'''\n",
    "        \n",
    "        elif isinstance(p, Treasure2) and 'h' in agent.holding:\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'GTreasure2'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "                '''This module handles when the agent is able to sense a type 2 treasure. It works in the same fashion as the last module with the\n",
    "                difference being that only disposable tools on inventory are considered in the first condition check and not any kind of tool as in\n",
    "                the previous module'''\n",
    "            \n",
    "        elif isinstance(p, DisposTool):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'Gdispos'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "                '''This module handles when the agent is able to sense a disposable tool. I simply checks if the tool is in the current location of the\n",
    "                agent to pick it up or otherwise move towards it calling the getDirection() function'''\n",
    "            \n",
    "        elif isinstance(p, ReuseTool):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'Greuse'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "                '''This module handles when the agent is able to sense a reusable tool. Works the same as the last module'''\n",
    "    \n",
    "    if not actionTaken:\n",
    "        return 'moveRandom'\n",
    "    \n",
    "def getDirection(origin, goal):\n",
    "    '''Decides an action that will move the agent one cell closer (in manhatan distance) to an object it wants to pick up'''\n",
    "    if origin[1] < goal[1]:\n",
    "        return 'moveRight'\n",
    "    elif origin[1] > goal[1]:\n",
    "        return 'moveLeft'\n",
    "    elif origin [0] > goal[0]:\n",
    "        return 'moveUp'\n",
    "    else:\n",
    "        return 'moveDown'\n",
    "    \n",
    "def templateEnv(size):\n",
    "    '''Creates an empty matrix to represent an enviroment or agent's percept'''\n",
    "    matrix = np.array([['-' for i in range (0, size + 2)] for j in range (0, size + 2)])\n",
    "    \n",
    "    #Make the matrix pretty with outer rol and col aesthetics\n",
    "    for i in range(0, size + 2):\n",
    "        for j in range(0, size + 2):\n",
    "            if (i == 0 and j == 0) or (i == size + 1 and j == size + 1):\n",
    "                matrix[i][j] = '\\\\'\n",
    "\n",
    "            elif (i == 0 and j == size + 1) or (i == size + 1 and j == 0):\n",
    "                matrix[i][j] = '/'\n",
    "\n",
    "            elif i == 0 and (j != 0 or j!= size + 1):\n",
    "                matrix[i][j] = str(j)\n",
    "            \n",
    "            elif i == size + 1 and (j != 0 or j!= size + 1):\n",
    "                matrix[i][j] = str(j)\n",
    "\n",
    "            elif (i != 0 or i != size + 1) and j == 0:\n",
    "                matrix[i][j] = str(i)\n",
    "            \n",
    "            elif (i != 0 or i != size + 1) and j == size + 1:\n",
    "                matrix[i][j] = str(i)\n",
    "    return matrix\n",
    "\n",
    "def fillEnv(matrix, things):\n",
    "    '''fills an empty matrix with objects in the environment at their proper locations'''\n",
    "    \n",
    "    for thing in things:\n",
    "        if isinstance(thing, Treasure1):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 'T'\n",
    "        elif isinstance(thing, Treasure2):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 't'\n",
    "        elif isinstance(thing, DisposTool):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 'h'\n",
    "        elif isinstance(thing, ReuseTool):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 'H'\n",
    "        elif isinstance(thing, Wall):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 'X'\n",
    "        \n",
    "    print('\\n'.join([''.join(['{:3}'.format(item) for item in row]) \n",
    "           for row in matrix]))\n",
    "    return matrix\n",
    "    \n",
    "def getUnknownsReflex(matrix, reference):\n",
    "    '''modifies the graphical representation of the agent's percept to reflect the cells it can't sense (for partial env)'''\n",
    "    for i in range(1, len(matrix) - 1):\n",
    "            for j in range(1, len(matrix) - 1):\n",
    "                \n",
    "                if [i, j] != reference:\n",
    "                    if [i+1, j] != reference and [i-1, j] != reference:\n",
    "                        if [i, j+1] != reference and [i, j-1] != reference:\n",
    "                            if [i+1, j+1] != reference and [i-1, j-1] != reference:\n",
    "                                if [i+1, j-1] != reference and [i-1, j+1] != reference:\n",
    "                                    matrix[i][j] = '?'\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def main(start=[1,1]):\n",
    "    '''Run the simple reflex hunter in the partial treasure island environment'''\n",
    "    partial_island = PartialIsland()\n",
    "    mike = ReflexHunter(reflexProgram)\n",
    "\n",
    "    #Create 3 objects of each kind to place on the environment\n",
    "    treasure1A = Treasure1()\n",
    "    treasure1B = Treasure1()\n",
    "    treasure1C = Treasure1()\n",
    "    treasure2A = Treasure2()\n",
    "    treasure2B = Treasure2()\n",
    "    treasure2C = Treasure2()\n",
    "    dispos1 = DisposTool()\n",
    "    dispos2 = DisposTool()\n",
    "    dispos3 = DisposTool()\n",
    "    reusable1 = ReuseTool()\n",
    "    reusable2 = ReuseTool()\n",
    "    reusable3 = ReuseTool()\n",
    "    wall = Wall()\n",
    "    wall2 = Wall()\n",
    "    wall3 = Wall()\n",
    "\n",
    "    partial_island.add_thing(mike, start)\n",
    "    mike.performance = 50 #prevents AIMA from resetting the performance to 0 when adding the agent to the environment\n",
    "    \n",
    "    #add things randomly preventing placing more than one item in a single cell in the environment\n",
    "    xy = [[1, 1],[1, 2],[1, 3],[1, 4],[1, 5],[1, 6],\n",
    "          [2, 1],[2, 2],[2, 3],[2, 4],[2, 5],[2, 6],\n",
    "          [3, 1],[3, 2],[3, 3],[3, 4],[3, 5],[3, 6],\n",
    "          [4, 1],[4, 2],[4, 3],[4, 4],[4, 5],[4, 6],\n",
    "          [5, 1],[5, 2],[5, 3],[5, 4],[5, 5],[5, 6],\n",
    "          [6, 1],[6, 2],[6, 3],[6, 4],[6, 5],[6, 6]]\n",
    "\n",
    "    partial_island.add_thing(treasure1A, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(treasure1B, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(treasure1C, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(reusable1, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(reusable2, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(reusable3, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(treasure2A, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(treasure2B, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(treasure2C, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(dispos1, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(dispos2, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(dispos3, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(wall, xy.pop(randint(0, len(xy)) - 1))\n",
    "    partial_island.add_thing(wall2, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(wall3, xy.pop(randint(0, len(xy) - 1)))\n",
    "\n",
    "    partial_island.run(50) #run the program for 50 iterations\n",
    "    return mike.performance #for studying several runs\n",
    "                                          \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell executes 500 runs of 50 iterations each of the previous agent and environment. The average agent performance of the runs is computed (takes less than a minute to run but its not inmediate please be patient). The agent location for these runs is also randomized like the location of the objects. Stdout is supressed to avoid excessive printing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "total_performance = 0\n",
    "for i in range (1, 500):\n",
    "    run_result = main(start=[randint(1, 6), randint(1, 6)]);\n",
    "    total_performance += run_result\n",
    "average_performance = total_performance / 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell prints the average agent performance from the last experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.446"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL-BASED REFLEX AGENT in FULLY OBSERVABLE ENVIRONMENT #\n",
    "\n",
    "This model works very similar to the first one (simple-reflex fully observable), but the main change lies in the agent having a built-in memory array for storing past percepts. This difference will be much more significant in the partially observable environment because here the whole grid is always available anyways, making this agent's memory not an actual advantage for this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Next cell runs a model-based reflex agent program in a fully observable environment. Output depicts the behavior of the agent for all the steps in a 50 iteration run with 3 items of each kind placed randomly in the environment. The starting position of the agent for this run is \\[1, 1\\]<b></b></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Location: [1, 1]\n",
      "Agent Tools: []\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - H - T 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 50\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [1, 2].\n",
      "Agent Location: [1, 2]\n",
      "Agent Tools: []\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - H - T 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 49\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [1, 3].\n",
      "Agent Location: [1, 3]\n",
      "Agent Tools: []\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - H - T 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 48\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [1, 4].\n",
      "Agent Location: [1, 4]\n",
      "Agent Tools: []\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - H - T 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 47\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Down to [2, 4].\n",
      "Agent Location: [2, 4]\n",
      "Agent Tools: []\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - H - T 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 46\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Grabbed Reusable Tool at [2, 4].\n",
      "Agent Location: [2, 4]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - T 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 46\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [2, 5].\n",
      "Agent Location: [2, 5]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - T 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 45\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [2, 6].\n",
      "Agent Location: [2, 6]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - T 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 44\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Grabbed Treasure1 at [2, 6].\n",
      "Agent Location: [2, 6]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 64\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Left to [2, 5].\n",
      "Agent Location: [2, 5]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 63\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Left to [2, 4].\n",
      "Agent Location: [2, 4]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 62\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Left to [2, 3].\n",
      "Agent Location: [2, 3]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 61\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Left to [2, 2].\n",
      "Agent Location: [2, 2]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 60\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Down to [3, 2].\n",
      "Agent Location: [3, 2]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - T H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 59\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Grabbed Treasure1 at [3, 2].\n",
      "Agent Location: [3, 2]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 79\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [3, 3].\n",
      "Agent Location: [3, 3]\n",
      "Agent Tools: ['H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - H H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 78\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Grabbed Reusable Tool at [3, 3].\n",
      "Agent Location: [3, 3]\n",
      "Agent Tools: ['H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 78\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [3, 4].\n",
      "Agent Location: [3, 4]\n",
      "Agent Tools: ['H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - H - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 77\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Grabbed Reusable Tool at [3, 4].\n",
      "Agent Location: [3, 4]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 77\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [3, 5].\n",
      "Agent Location: [3, 5]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 76\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [3, 6].\n",
      "Agent Location: [3, 6]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - h 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 75\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Grabbed Disposable Tool at [3, 6].\n",
      "Agent Location: [3, 6]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 75\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Left to [3, 5].\n",
      "Agent Location: [3, 5]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 74\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Left to [3, 4].\n",
      "Agent Location: [3, 4]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 73\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Up to [2, 4].\n",
      "Agent Location: [2, 4]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 72\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Up to [1, 4].\n",
      "Agent Location: [1, 4]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - t - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 71\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Grabbed Treasure2 at [1, 4].\n",
      "Agent Location: [1, 4]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 111\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [1, 5].\n",
      "Agent Location: [1, 5]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 110\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [1, 6].\n",
      "Agent Location: [1, 6]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 109\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Down to [2, 6].\n",
      "Agent Location: [2, 6]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 108\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Down to [3, 6].\n",
      "Agent Location: [3, 6]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 107\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Down to [4, 6].\n",
      "Agent Location: [4, 6]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - h 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 106\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Grabbed Disposable Tool at [4, 6].\n",
      "Agent Location: [4, 6]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 106\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Left to [4, 5].\n",
      "Agent Location: [4, 5]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 105\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Left to [4, 4].\n",
      "Agent Location: [4, 4]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 104\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Left to [4, 3].\n",
      "Agent Location: [4, 3]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 103\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Left to [4, 2].\n",
      "Agent Location: [4, 2]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 102\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Left to [4, 1].\n",
      "Agent Location: [4, 1]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 101\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Up to [3, 1].\n",
      "Agent Location: [3, 1]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 100\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Up to [2, 1].\n",
      "Agent Location: [2, 1]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 t - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 99\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Grabbed Treasure2 at [2, 1].\n",
      "Agent Location: [2, 1]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 139\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [2, 2].\n",
      "Agent Location: [2, 2]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 138\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [2, 3].\n",
      "Agent Location: [2, 3]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 137\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Down to [3, 3].\n",
      "Agent Location: [3, 3]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 136\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Down to [4, 3].\n",
      "Agent Location: [4, 3]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 135\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Down to [5, 3].\n",
      "Agent Location: [5, 3]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - h - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 134\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Grabbed Disposable Tool at [5, 3].\n",
      "Agent Location: [5, 3]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - - - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 134\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [5, 4].\n",
      "Agent Location: [5, 4]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - - - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 133\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Up to [4, 4].\n",
      "Agent Location: [4, 4]\n",
      "Agent Tools: ['H', 'H', 'H', 'h']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - t - - 4 \n",
      "5 - - - - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 132\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Grabbed Treasure2 at [4, 4].\n",
      "Agent Location: [4, 4]\n",
      "Agent Tools: ['H', 'H', 'H']\n",
      "\n",
      "\\ 1 2 3 4 5 6 / \n",
      "1 - - - - - - 1 \n",
      "2 - - - - - - 2 \n",
      "3 - - - - - - 3 \n",
      "4 - - - - - - 4 \n",
      "5 - - - - T X 5 \n",
      "6 X - - - - X 6 \n",
      "/ 1 2 3 4 5 6 \\ \n",
      "Agent performance: 172\n",
      "INTERNAL STATE:\n",
      "[[1, 2], [1, 3]]\n",
      "Hunter: Moved Right to [4, 5].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents import *\n",
    "from random import *\n",
    "\n",
    "\n",
    "class Treasure1(Thing):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Treasure2(Thing):\n",
    "    pass\n",
    "\n",
    "\n",
    "class DisposTool(Thing):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ReuseTool(Thing):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Island(Environment):\n",
    "    def __init__(self, width=7, height=7):\n",
    "        super(Island, self).__init__()\n",
    "\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        # Sets iteration start and end (no walls).\n",
    "        # self.x_start, self.y_start = (0, 0)\n",
    "        # self.x_end, self.y_end = (self.width, self.height)\n",
    "\n",
    "    def percept(self, agent):\n",
    "        '''prints & return a list of things that are in our agent's location'''\n",
    "        percepts = []\n",
    "        locations = []\n",
    "        # locations = self.getLocations(agent.location)\n",
    "        # TODO: implement 'getLocations function\n",
    "        for i in range(1,7):\n",
    "            for j in range(1,7):\n",
    "                locations.append([i,j])\n",
    "\n",
    "        for location in locations:\n",
    "            things = self.list_things_at(location)\n",
    "            for thing in things:\n",
    "                percepts.append(thing)\n",
    "        return percepts\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        # TODO: check for walls and boundaries\n",
    "        if action == 'moveRandom':\n",
    "            direction = randint(1, 4)\n",
    "            print(\"Hunter: Moved random\")\n",
    "            if direction == 1:\n",
    "                action = 'moveRight'\n",
    "            elif direction == 2:\n",
    "                action = 'moveLeft'\n",
    "            elif direction == 3:\n",
    "                action = 'moveUp'\n",
    "            elif direction == 4:\n",
    "                action = 'moveDown'\n",
    "\n",
    "        if action == 'moveRight':\n",
    "            if agent.location[1] < 6:\n",
    "                walls = self.list_things_at([agent.location[0], agent.location[1]+1], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveRight()\n",
    "                agent.performance -= 1\n",
    "            else:\n",
    "                agent.performance -= 5\n",
    "        elif action == 'moveLeft':\n",
    "            if agent.location[1] > 1:\n",
    "                walls = self.list_things_at([agent.location[0], agent.location[1] - 1], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveLeft()\n",
    "                agent.performance -= 1\n",
    "            else:\n",
    "                agent.performance -= 5\n",
    "        elif action == 'moveUp':\n",
    "            if agent.location[0] > 1:\n",
    "                walls = self.list_things_at([agent.location[0]-1, agent.location[1]], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveUp()\n",
    "                agent.performance -= 1\n",
    "            else:\n",
    "                agent.performance -= 5\n",
    "        elif action == 'moveDown':\n",
    "            if agent.location[0] < 6:\n",
    "                walls = self.list_things_at([agent.location[0] + 1, agent.location[1]], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveDown()\n",
    "                agent.performance -= 1\n",
    "            else:\n",
    "                agent.performance -= 5\n",
    "        elif action == \"Greuse\":\n",
    "            items = self.list_things_at(agent.location, tclass=ReuseTool)\n",
    "            if len(items) != 0:\n",
    "                if agent.greuse(items[0]):  #\n",
    "                    self.delete_thing(items[0])  #\n",
    "                    agent.holding.append('H')\n",
    "        elif action == \"Gdispos\":\n",
    "            agent.gdispos()\n",
    "            items = self.list_things_at(agent.location, tclass=DisposTool)\n",
    "            if len(items) != 0:\n",
    "                if agent.gdispos(items[0]):  #\n",
    "                    self.delete_thing(items[0])  # D\n",
    "                    agent.holding.append('h')\n",
    "        elif action == \"GTreasure1\":\n",
    "            items = self.list_things_at(agent.location, tclass=Treasure1)\n",
    "            if len(items) != 0:\n",
    "                if agent.gTreasure1(items[0]):  # Grab Treasure 1\n",
    "                    # TODO: add to performance\n",
    "                    agent.performance += 20\n",
    "                    self.delete_thing(items[0])  # Delete it from the Island after.\n",
    "        elif action == \"GTreasure2\":\n",
    "            items = self.list_things_at(agent.location, tclass=Treasure2)\n",
    "            if len(items) != 0:\n",
    "                if agent.gTreasure2(items[0]):  # Grab Treasure2\n",
    "                    agent.performance += 40\n",
    "                    agent.holding.remove('h')\n",
    "                    self.delete_thing(items[0])  # Delete it from the Island after.\n",
    "        elif action == \"NoOp\":\n",
    "            pass\n",
    "\n",
    "    def is_done(self):\n",
    "        '''By default, we're done when we can't find a live agent,\n",
    "        but to prevent killing our cute dog, we will or it with when there is no more food or water'''\n",
    "        no_edibles = not any(isinstance(thing, Treasure1) or isinstance(thing, DisposTool) or isinstance(thing, ReuseTool) or isinstance(thing, Treasure2) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n",
    "\n",
    "    def step(self): #AIMA function overriden to access agent status in each step of a run and print the performance\n",
    "        \"\"\"Run the environment for one time step. If the\n",
    "        actions and exogenous changes are independent, this method will\n",
    "        do.  If there are interactions between them, you'll need to\n",
    "        override this method.\"\"\"\n",
    "        if not self.is_done():\n",
    "            actions = []\n",
    "            for agent in self.agents:\n",
    "                if agent.alive:\n",
    "                    actions.append(agent.program(self.percept(agent), agent))\n",
    "                else:\n",
    "                    actions.append(\"\")\n",
    "                \n",
    "            for (agent, action) in zip(self.agents, actions):\n",
    "                self.execute_action(agent, action)\n",
    "            self.exogenous_change()\n",
    "\n",
    "class ReflexHunter(Agent):\n",
    "    def __init__(self, program=None):  # default state of the agent\n",
    "        self.alive = True\n",
    "        self.bump = False\n",
    "        self.type = 'simple_reflex'\n",
    "        self.holding = []\n",
    "        self.performance = 50\n",
    "        if program is None:\n",
    "            def program(percept):\n",
    "                return eval(input('Percept={}; action? '.format(percept)))\n",
    "        # assert isinstance(program, collections.Callable)\n",
    "        self.program = program\n",
    "\n",
    "    def moveRight(self):\n",
    "        self.location[1] += 1\n",
    "        print(\"Hunter: Moved Right to {}.\".format(self.location))\n",
    "\n",
    "    def moveLeft(self):\n",
    "        self.location[1] -= 1\n",
    "        print(\"Hunter: Moved Left to {}.\".format(self.location))\n",
    "\n",
    "    def moveUp(self):\n",
    "        self.location[0] -= 1\n",
    "        print(\"Hunter: Moved Up to {}.\".format(self.location))\n",
    "\n",
    "    def moveDown(self):\n",
    "        self.location[0] += 1\n",
    "        print(\"Hunter: Moved Down to {}.\".format(self.location))\n",
    "\n",
    "    def greuse(self, thing):\n",
    "        '''returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, ReuseTool):\n",
    "            print(\"Hunter: Grabbed Reusable Tool at {}.\".format(self.location))\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def gdispos(self, thing = None):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, DisposTool):\n",
    "            print(\"Hunter: Grabbed Disposable Tool at {}.\".format(self.location))\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def gTreasure1(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Treasure1):\n",
    "            print(\"Hunter: Grabbed Treasure1 at {}.\".format(self.location))\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def gTreasure2(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Treasure2):\n",
    "            print(\"Hunter: Grabbed Treasure2 at {}.\".format(self.location))\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "class ModelBasedHunter(ReflexHunter):\n",
    "    def __init__(self, program=None):  # default state of the agent\n",
    "        self.alive = True\n",
    "        self.bump = False\n",
    "        self.holding = []\n",
    "        self.performance = 50\n",
    "        self.type = \"modelbased\"\n",
    "        self.seen = [[1,2], [1,3]]\n",
    "        if program is None:\n",
    "            def program(percept):\n",
    "                return eval(input('Percept={}; action? '.format(percept)))\n",
    "        # assert isinstance(program, collections.Callable)\n",
    "        self.program = program\n",
    "    \n",
    "def program(percepts, agent):\n",
    "    '''Returns an action based on it's percepts'''\n",
    "    print(\"Agent Location: \" + str(agent.location))\n",
    "    print(\"Agent Tools: \" + str(agent.holding))\n",
    "    printMatrix(percepts)\n",
    "    print(\"\")\n",
    "    print(\"Agent performance: \" + str(agent.performance))\n",
    "    if agent.type == 'modelbased':\n",
    "        print(\"INTERNAL STATE:\")\n",
    "        print(agent.seen)\n",
    "    actionTaken = False\n",
    "    for p in percepts:\n",
    "        # Grab actions for when agent is in same location\n",
    "        if actionTaken:\n",
    "            break\n",
    "        in_location = agent.location == p.location\n",
    "        if isinstance(p, Treasure1) and inInventory('H', agent):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'GTreasure1'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "        elif isinstance(p, Treasure2) and inInventory('h', agent):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'GTreasure2'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "        elif isinstance(p, DisposTool):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'Gdispos'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "        elif isinstance(p, ReuseTool):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'Greuse'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "\n",
    "    if not actionTaken:\n",
    "        return 'moveRandom'\n",
    "\n",
    "def printMatrix(percepts):\n",
    "    for i in range(0, 8):\n",
    "        print(\"\")\n",
    "        for j in range(0, 8):\n",
    "            if (i == 0 and j == 0) or (i == 7 and j == 7):\n",
    "                print(\"\\\\\", end=\" \")\n",
    "\n",
    "            elif (i == 0 and j == 7) or (i == 7 and j == 0):\n",
    "                print(\"/\", end=\" \")\n",
    "\n",
    "            elif (i == 0 or i == 7):\n",
    "                print(\"\".join(str(j)), end=\" \")\n",
    "\n",
    "            elif (j == 0 or j == 7):\n",
    "                print(\"\".join(str(i)), end=\" \")\n",
    "\n",
    "            else:\n",
    "                #Check percepts, print if matches location\n",
    "                printed = False\n",
    "                for p in percepts:\n",
    "                    if p.location == [i,j]:\n",
    "                        if isinstance(p, Treasure1):\n",
    "                            printed = True\n",
    "                            print(\"T\", end=\" \")\n",
    "                        elif isinstance(p, Treasure2):\n",
    "                            printed = True\n",
    "                            print(\"t\", end=\" \")\n",
    "                        elif isinstance(p, DisposTool):\n",
    "                            printed = True\n",
    "                            print(\"h\", end=\" \")\n",
    "                        elif isinstance(p, ReuseTool):\n",
    "                            printed = True\n",
    "                            print(\"H\", end=\" \")\n",
    "                        elif isinstance(p, Wall):\n",
    "                            printed = True\n",
    "                            print(\"X\", end=\" \")\n",
    "                if not printed:\n",
    "                    print(\"-\", end=\" \")\n",
    "\n",
    "\n",
    "def inInventory(tool, agent):\n",
    "    for hold in agent.holding:\n",
    "        if hold == tool:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def getDirection(origin, goal):\n",
    "    if origin[1] < goal[1]:\n",
    "        return 'moveRight'\n",
    "    elif origin[1] > goal[1]:\n",
    "        return 'moveLeft'\n",
    "    elif origin[0] > goal[0]:\n",
    "        return 'moveUp'\n",
    "    else:\n",
    "        return 'moveDown'\n",
    "    \n",
    "def main(start = [1, 1]):\n",
    "    '''Run the simple reflex hunter in the partial treasure island environment'''\n",
    "    island = Island()\n",
    "    charlie = ModelBasedHunter(program)\n",
    "\n",
    "    #Create 3 objects of each kind to place on the environment\n",
    "    treasure1A = Treasure1()\n",
    "    treasure1B = Treasure1()\n",
    "    treasure1C = Treasure1()\n",
    "    treasure2A = Treasure2()\n",
    "    treasure2B = Treasure2()\n",
    "    treasure2C = Treasure2()\n",
    "    dispos1 = DisposTool()\n",
    "    dispos2 = DisposTool()\n",
    "    dispos3 = DisposTool()\n",
    "    reusable1 = ReuseTool()\n",
    "    reusable2 = ReuseTool()\n",
    "    reusable3 = ReuseTool()\n",
    "    wall = Wall()\n",
    "    wall2 = Wall()\n",
    "    wall3 = Wall()\n",
    "    \n",
    "    #add things randomly preventing placing more than one item in a single cell in the environment\n",
    "    xy = [[1, 1],[1, 2],[1, 3],[1, 4],[1, 5],[1, 6],\n",
    "          [2, 1],[2, 2],[2, 3],[2, 4],[2, 5],[2, 6],\n",
    "          [3, 1],[3, 2],[3, 3],[3, 4],[3, 5],[3, 6],\n",
    "          [4, 1],[4, 2],[4, 3],[4, 4],[4, 5],[4, 6],\n",
    "          [5, 1],[5, 2],[5, 3],[5, 4],[5, 5],[5, 6],\n",
    "          [6, 1],[6, 2],[6, 3],[6, 4],[6, 5],[6, 6]]\n",
    "\n",
    "    island.add_thing(charlie, start)\n",
    "    charlie.performance = 50 #prevents AIMA from resetting the performance to 0 when adding the agent to the environment\n",
    "\n",
    "    island.add_thing(treasure1A, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(treasure1B, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(treasure1C, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(reusable1, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(reusable2, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(reusable3, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(treasure2A, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(treasure2B, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(treasure2C, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(dispos1, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(dispos2, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(dispos3, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(wall, xy.pop(randint(0, len(xy)) - 1))\n",
    "    island.add_thing(wall2, xy.pop(randint(0, len(xy) - 1)))\n",
    "    island.add_thing(wall3, xy.pop(randint(0, len(xy) - 1)))\n",
    "\n",
    "    island.run(50) #run the program for 50 iterations\n",
    "    return charlie.performance #for studying several runs\n",
    "                                          \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell executes 500 runs of 50 iterations each of the previous agent and environment. The average agent performance of the runs is computed (takes less than a minute to run but its not inmediate please be patient). The agent location for these runs is also randomized like the location of the objects. Stdout is supressed to avoid excessive printing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "total_performance = 0\n",
    "for i in range (1, 500):\n",
    "    run_result = main(start=[randint(1, 6), randint(1, 6)]);\n",
    "    total_performance += run_result\n",
    "average_performance = total_performance / 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell prints the average agent performance from the last experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.96"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL-BASED REFLEX AGENT in PARTIALLY OBSERVABLE ENVIRONMENT #\n",
    "\n",
    "This time around the agent takes full advantage of its memory capabilities and stores useful objects it was able to sense at some point during the run. During the first step of a run the whole percept is appended to the memory. For the remaining of the steps it is checked wether or not a new array of percepts actually contains new objects not previously seen before. If that is the case they are added to the memory. It is worth mentioning that this particular model only remembers relevant objects in memory and not actually empty spaces, so empty spaces that are not adjacent to the agent will return to a \"?\" status from a \"-\" status (empty)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Next cell runs a model-based reflex agent program in a partially observable environment. Output depicts the behavior of the agent for all the steps in a 50 iteration run with 3 items of each kind placed randomly in the environment. The starting position of the agent for this run is \\[1, 1\\]<b></b></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL-BASED REFLEX AGENT in PARTIALLY OBSERVABLE ENVIRONMENT\n",
      "<STARTING>\n",
      "Agent location: [1, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  T  -  -  X  2  \n",
      "3  t  -  H  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "Agent performance: 50\n",
      "\n",
      "<STEP1>\n",
      "PERCEPT\n",
      "Agent location: [1, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  ?  ?  ?  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 49\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  T  -  -  X  2  \n",
      "3  t  -  H  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP2>\n",
      "PERCEPT\n",
      "Agent location: [2, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  ?  ?  ?  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  t  -  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 44\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  T  -  -  X  2  \n",
      "3  t  -  H  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP3>\n",
      "PERCEPT\n",
      "Agent location: [2, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  ?  ?  ?  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  t  -  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 39\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  T  -  -  X  2  \n",
      "3  t  -  H  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP4>\n",
      "PERCEPT\n",
      "Agent location: [2, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  ?  ?  ?  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  t  -  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 34\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  T  -  -  X  2  \n",
      "3  t  -  H  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP5>\n",
      "PERCEPT\n",
      "Agent location: [2, 1]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  ?  ?  ?  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  t  -  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 33\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 2]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  T  -  -  X  2  \n",
      "3  t  -  H  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP6>\n",
      "PERCEPT\n",
      "Agent location: [2, 2]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  ?  ?  ?  1  \n",
      "2  -  -  T  ?  ?  ?  2  \n",
      "3  t  -  H  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 32\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 3]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  T  -  -  X  2  \n",
      "3  t  -  H  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP7>\n",
      "PERCEPT\n",
      "Agent location: [2, 3]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  -  -  T  ?  ?  1  \n",
      "2  ?  -  T  -  ?  ?  2  \n",
      "3  t  -  H  -  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 31\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 3]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  T  -  -  X  2  \n",
      "3  t  -  H  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP8>\n",
      "PERCEPT\n",
      "Agent location: [3, 3]\n",
      "Agent tools: []\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  T  ?  ?  1  \n",
      "2  ?  -  T  -  ?  ?  2  \n",
      "3  t  -  H  -  ?  ?  3  \n",
      "4  ?  h  -  -  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Greuse\n",
      "NEW AGENT'S PERFORMANCE: 30\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  T  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP9>\n",
      "PERCEPT\n",
      "Agent location: [3, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  T  ?  ?  1  \n",
      "2  ?  -  T  -  ?  ?  2  \n",
      "3  t  -  -  -  ?  ?  3  \n",
      "4  ?  h  -  -  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 29\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  T  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP10>\n",
      "PERCEPT\n",
      "Agent location: [2, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  -  -  T  ?  ?  1  \n",
      "2  ?  -  T  -  ?  ?  2  \n",
      "3  t  -  -  -  ?  ?  3  \n",
      "4  ?  h  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: GTreas1\n",
      "NEW AGENT'S PERFORMANCE: 49\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP11>\n",
      "PERCEPT\n",
      "Agent location: [2, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  -  -  T  ?  ?  1  \n",
      "2  ?  -  -  -  ?  ?  2  \n",
      "3  t  -  -  -  ?  ?  3  \n",
      "4  ?  h  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 48\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 4]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP12>\n",
      "PERCEPT\n",
      "Agent location: [2, 4]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  -  T  X  ?  1  \n",
      "2  ?  ?  -  -  -  ?  2  \n",
      "3  t  ?  -  -  -  ?  3  \n",
      "4  ?  h  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 47\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  T  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP13>\n",
      "PERCEPT\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  -  T  X  ?  1  \n",
      "2  ?  ?  -  -  -  ?  2  \n",
      "3  t  ?  ?  ?  ?  ?  3  \n",
      "4  ?  h  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: GTreas1\n",
      "NEW AGENT'S PERFORMANCE: 67\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP14>\n",
      "PERCEPT\n",
      "Agent location: [1, 4]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  -  -  X  ?  1  \n",
      "2  ?  ?  -  -  -  ?  2  \n",
      "3  t  ?  ?  ?  ?  ?  3  \n",
      "4  ?  h  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 66\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP15>\n",
      "PERCEPT\n",
      "Agent location: [1, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  -  -  -  X  ?  1  \n",
      "2  ?  -  -  -  ?  ?  2  \n",
      "3  t  ?  ?  ?  ?  ?  3  \n",
      "4  ?  h  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 65\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [1, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP16>\n",
      "PERCEPT\n",
      "Agent location: [1, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  ?  X  ?  1  \n",
      "2  -  -  -  ?  ?  ?  2  \n",
      "3  t  ?  ?  ?  ?  ?  3  \n",
      "4  ?  h  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 64\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP17>\n",
      "PERCEPT\n",
      "Agent location: [2, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  ?  X  ?  1  \n",
      "2  -  -  -  ?  ?  ?  2  \n",
      "3  t  -  -  ?  ?  ?  3  \n",
      "4  ?  h  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 63\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP18>\n",
      "PERCEPT\n",
      "Agent location: [3, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  -  -  -  ?  ?  ?  2  \n",
      "3  t  -  -  ?  ?  ?  3  \n",
      "4  -  h  -  ?  ?  ?  4  \n",
      "5  ?  ?  ?  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 62\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [4, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  h  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP19>\n",
      "PERCEPT\n",
      "Agent location: [4, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  t  -  -  ?  ?  ?  3  \n",
      "4  -  h  -  ?  ?  ?  4  \n",
      "5  -  -  T  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Gdispos\n",
      "NEW AGENT'S PERFORMANCE: 60\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [4, 2]\n",
      "Agent tools: ['H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP20>\n",
      "PERCEPT\n",
      "Agent location: [4, 2]\n",
      "Agent tools: ['H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  t  -  -  ?  ?  ?  3  \n",
      "4  -  -  -  ?  ?  ?  4  \n",
      "5  -  -  T  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 59\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [4, 1]\n",
      "Agent tools: ['H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP21>\n",
      "PERCEPT\n",
      "Agent location: [4, 1]\n",
      "Agent tools: ['H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  t  -  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  -  -  T  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 58\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 1]\n",
      "Agent tools: ['H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  t  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP22>\n",
      "PERCEPT\n",
      "Agent location: [3, 1]\n",
      "Agent tools: ['H', 'h']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  t  -  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  ?  ?  T  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: GTreas2\n",
      "NEW AGENT'S PERFORMANCE: 98\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 1]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP23>\n",
      "PERCEPT\n",
      "Agent location: [3, 1]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  -  -  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  ?  ?  T  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 97\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP24>\n",
      "PERCEPT\n",
      "Agent location: [3, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  -  -  -  ?  ?  ?  2  \n",
      "3  -  -  -  ?  ?  ?  3  \n",
      "4  -  -  -  ?  ?  ?  4  \n",
      "5  ?  ?  T  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 96\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP25>\n",
      "PERCEPT\n",
      "Agent location: [3, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  -  -  -  ?  ?  2  \n",
      "3  ?  -  -  -  ?  ?  3  \n",
      "4  ?  -  -  -  ?  ?  4  \n",
      "5  ?  ?  T  ?  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 95\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [4, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP26>\n",
      "PERCEPT\n",
      "Agent location: [4, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  -  -  -  ?  ?  3  \n",
      "4  ?  -  -  -  ?  ?  4  \n",
      "5  ?  -  T  t  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 94\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [5, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  T  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP27>\n",
      "PERCEPT\n",
      "Agent location: [5, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  -  -  -  ?  ?  4  \n",
      "5  ?  -  T  t  ?  ?  5  \n",
      "6  ?  H  -  -  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: GTreas1\n",
      "NEW AGENT'S PERFORMANCE: 114\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [5, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP28>\n",
      "PERCEPT\n",
      "Agent location: [5, 3]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  -  -  -  ?  ?  4  \n",
      "5  ?  -  -  t  ?  ?  5  \n",
      "6  ?  H  -  -  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 113\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [5, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP29>\n",
      "PERCEPT\n",
      "Agent location: [5, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  -  -  -  ?  ?  ?  4  \n",
      "5  -  -  -  t  ?  ?  5  \n",
      "6  -  H  -  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 112\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [6, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  H  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP30>\n",
      "PERCEPT\n",
      "Agent location: [6, 2]\n",
      "Agent tools: ['H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  -  -  -  t  ?  ?  5  \n",
      "6  -  H  -  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Greuse\n",
      "NEW AGENT'S PERFORMANCE: 111\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [6, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP31>\n",
      "PERCEPT\n",
      "Agent location: [6, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  -  -  -  t  ?  ?  5  \n",
      "6  -  -  -  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 110\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [6, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP32>\n",
      "PERCEPT\n",
      "Agent location: [6, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  -  -  ?  t  ?  ?  5  \n",
      "6  -  -  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 109\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [5, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP33>\n",
      "PERCEPT\n",
      "Agent location: [5, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  -  -  ?  t  ?  ?  5  \n",
      "6  -  -  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 108\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [6, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP34>\n",
      "PERCEPT\n",
      "Agent location: [6, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  -  -  ?  t  ?  ?  5  \n",
      "6  -  -  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 107\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [5, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP35>\n",
      "PERCEPT\n",
      "Agent location: [5, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  -  -  ?  t  ?  ?  5  \n",
      "6  -  -  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 102\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [5, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP36>\n",
      "PERCEPT\n",
      "Agent location: [5, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  -  -  ?  t  ?  ?  5  \n",
      "6  -  -  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 97\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [5, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP37>\n",
      "PERCEPT\n",
      "Agent location: [5, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  -  -  ?  t  ?  ?  5  \n",
      "6  -  -  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 96\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [4, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP38>\n",
      "PERCEPT\n",
      "Agent location: [4, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  -  -  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  -  -  ?  t  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 95\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP39>\n",
      "PERCEPT\n",
      "Agent location: [3, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  -  -  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  t  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 90\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP40>\n",
      "PERCEPT\n",
      "Agent location: [3, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  -  -  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  t  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 85\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP41>\n",
      "PERCEPT\n",
      "Agent location: [3, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  -  -  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  t  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 84\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP42>\n",
      "PERCEPT\n",
      "Agent location: [3, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  -  -  -  ?  ?  ?  2  \n",
      "3  -  -  -  ?  ?  ?  3  \n",
      "4  -  -  -  ?  ?  ?  4  \n",
      "5  ?  ?  ?  t  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Up\n",
      "NEW AGENT'S PERFORMANCE: 83\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP43>\n",
      "PERCEPT\n",
      "Agent location: [2, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  ?  X  ?  1  \n",
      "2  -  -  -  ?  ?  ?  2  \n",
      "3  -  -  -  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  t  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Left\n",
      "NEW AGENT'S PERFORMANCE: 82\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP44>\n",
      "PERCEPT\n",
      "Agent location: [2, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  ?  ?  X  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  -  -  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  t  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 77\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [2, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP45>\n",
      "PERCEPT\n",
      "Agent location: [2, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  ?  ?  X  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  -  -  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  t  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 76\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP46>\n",
      "PERCEPT\n",
      "Agent location: [3, 1]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  -  -  ?  ?  ?  ?  2  \n",
      "3  -  -  ?  ?  ?  ?  3  \n",
      "4  -  -  ?  ?  ?  ?  4  \n",
      "5  ?  ?  ?  t  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Right\n",
      "NEW AGENT'S PERFORMANCE: 75\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [3, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP47>\n",
      "PERCEPT\n",
      "Agent location: [3, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  -  -  -  ?  ?  ?  2  \n",
      "3  -  -  -  ?  ?  ?  3  \n",
      "4  -  -  -  ?  ?  ?  4  \n",
      "5  ?  ?  ?  t  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 74\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [4, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP48>\n",
      "PERCEPT\n",
      "Agent location: [4, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  -  -  -  ?  ?  ?  3  \n",
      "4  -  -  -  ?  ?  ?  4  \n",
      "5  -  -  -  t  ?  ?  5  \n",
      "6  ?  ?  ?  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 73\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [5, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP49>\n",
      "PERCEPT\n",
      "Agent location: [5, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  -  -  -  ?  ?  ?  4  \n",
      "5  -  -  -  t  ?  ?  5  \n",
      "6  -  -  -  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: Down\n",
      "NEW AGENT'S PERFORMANCE: 72\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [6, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "<STEP50>\n",
      "PERCEPT\n",
      "Agent location: [6, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  ?  ?  ?  ?  X  ?  1  \n",
      "2  ?  ?  ?  ?  ?  ?  2  \n",
      "3  ?  ?  ?  ?  ?  ?  3  \n",
      "4  ?  ?  ?  ?  ?  ?  4  \n",
      "5  -  -  -  t  ?  ?  5  \n",
      "6  -  -  -  ?  ?  ?  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "SELECTED ACTION: Random\n",
      "SELECTED ACTION: canceled, tried to move out of bounds\n",
      "NEW AGENT'S PERFORMANCE: 67\n",
      "NEW ENVIRONMENT STATE\n",
      "Agent location: [6, 2]\n",
      "Agent tools: ['H', 'H']\n",
      "\\  1  2  3  4  5  6  /  \n",
      "1  -  -  -  -  X  -  1  \n",
      "2  -  -  -  -  -  X  2  \n",
      "3  -  -  -  -  -  h  3  \n",
      "4  -  -  -  -  h  t  4  \n",
      "5  -  -  -  t  -  -  5  \n",
      "6  -  -  -  -  H  X  6  \n",
      "/  1  2  3  4  5  6  \\  \n",
      "\n",
      "FINAL AGENT's PERFORMANCE: 67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the libraries used for constructing this agent and environment\n",
    "from agents import *\n",
    "from random import *\n",
    "import numpy as np\n",
    "\n",
    "#Create the classes of the objects placed in the enviroments\n",
    "class Treasure1(Thing):\n",
    "    pass\n",
    "\n",
    "class Treasure2(Thing):\n",
    "    pass\n",
    "\n",
    "class DisposTool(Thing):\n",
    "    pass\n",
    "\n",
    "class ReuseTool(Thing):\n",
    "    pass\n",
    "\n",
    "class Wall(Thing):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "#Create a partially observable class for the environment\n",
    "class PartialIsland(Environment):\n",
    "    def __init__(self, width=7, height=7): #Default shape of the environment is square 7x7\n",
    "        super(PartialIsland, self).__init__()\n",
    "\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "    \n",
    "    def percept(self, agent): #returns a list of objects that the given agent can sense\n",
    "        self.percepts = []\n",
    "        \n",
    "        locations = self.getPartialLocations(agent.location) #coordinates used to fetch the objects perceivable by the agent\n",
    "\n",
    "        for locus in locations:\n",
    "            things = self.list_things_at(locus)\n",
    "            for thing in things:\n",
    "                self.percepts.append(thing)\n",
    "        return self.percepts\n",
    "    \n",
    "    def getPartialLocations(self, agent_locus): #returns a list of coordinates of the cells adjacent to the current agent's position\n",
    "        here = [agent_locus[0], agent_locus[1]]\n",
    "        up = [agent_locus[0] - 1, agent_locus[1]]\n",
    "        upright = [agent_locus[0] - 1, agent_locus[1] + 1]\n",
    "        right = [agent_locus[0], agent_locus[1] + 1]\n",
    "        downright = [agent_locus[0] + 1, agent_locus[1] + 1]\n",
    "        down = [agent_locus[0] + 1, agent_locus[1]]\n",
    "        downleft = [agent_locus[0] + 1, agent_locus[1] - 1]\n",
    "        left = [agent_locus[0], agent_locus[1] - 1]\n",
    "        upleft = [agent_locus[0] - 1, agent_locus[1] - 1]\n",
    "        \n",
    "        locations = [here, up, upright, right, downright, down, downleft, left, upleft]\n",
    "        return locations\n",
    "    \n",
    "            \n",
    "    def execute_action(self, agent, action): #this function is called when running the environment after the agent's program returns an action\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        \n",
    "        if action == 'moveRandom':\n",
    "            direction = randint(1, 4)\n",
    "            print(\"SELECTED ACTION: Random\")\n",
    "            if direction == 1:\n",
    "                action = 'moveRight'\n",
    "            elif direction == 2:\n",
    "                action = 'moveLeft'\n",
    "            elif direction == 3:\n",
    "                action = 'moveUp'\n",
    "            elif direction == 4:\n",
    "                action = 'moveDown'\n",
    "                '''This module handles the case when the agent percieved only walls or empty spaces in the cells adjacent to it. The agent in this\n",
    "                case decides to prepare a random movement action. Another case of this module being called is when the agent is able to percieve\n",
    "                a treasure but it does not hold a tool that can unlock it. This scenario is effectively the same as ignoring the treasure.'''\n",
    "\n",
    "        if action == 'moveRight':\n",
    "            if agent.location[1] < 6:\n",
    "                walls = self.list_things_at([agent.location[0], agent.location[1]+1], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveRight()\n",
    "                    print(\"SELECTED ACTION: Right\")\n",
    "                else:\n",
    "                    agent.NoOp()\n",
    "            else:\n",
    "                print(\"SELECTED ACTION: canceled, tried to move out of bounds\")\n",
    "                agent.performance -= 5\n",
    "                '''This module handles the case when the agent decided to move right. First a check is performed to see if the agent decided to move out\n",
    "                of bounds, in this case the agent's location does not change in the environment and 5 points are deducted from the performance for the\n",
    "                agent's intent. If the move was in-bounds then it is checked wether or not the destination cell contains a wall; if this is the case the\n",
    "                agent's decision to move is changed to standing still, otherwise the agent moves and its location is updated in the env successfully'''\n",
    "                        \n",
    "        elif action == 'moveLeft':\n",
    "            if agent.location[1] > 1:\n",
    "                walls = self.list_things_at([agent.location[0], agent.location[1]-1], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveLeft()\n",
    "                    print(\"SELECTED ACTION: Left\")\n",
    "                else:\n",
    "                    agent.NoOp()\n",
    "            else:\n",
    "                print(\"SELECTED ACTION: canceled, tried to move out of bounds\")\n",
    "                agent.performance -= 5\n",
    "                '''This module handles the case when the agent decided to move left. It follows the same logic as the previous module'''\n",
    "        \n",
    "        elif action == 'moveUp':\n",
    "            if agent.location[0] > 1:\n",
    "                walls = self.list_things_at([agent.location[0] - 1, agent.location[1]], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveUp()\n",
    "                    print(\"SELECTED ACTION: Up\")\n",
    "                else:\n",
    "                    agent.NoOp()\n",
    "            else:\n",
    "                print(\"SELECTED ACTION: canceled, tried to move out of bounds\")\n",
    "                agent.performance -= 5\n",
    "                '''This module handles the case when the agent decided to move up. It follows the same logic as the previous module'''\n",
    "                \n",
    "        elif action == 'moveDown':\n",
    "            if agent.location[0] < 6:\n",
    "                walls = self.list_things_at([agent.location[0] + 1, agent.location[1]], tclass=Wall)\n",
    "                if len(walls) == 0:\n",
    "                    agent.moveDown()\n",
    "                    print(\"SELECTED ACTION: Down\")\n",
    "                else:\n",
    "                    agent.NoOp()\n",
    "            else:\n",
    "                print(\"SELECTED ACTION: canceled, tried to move out of bounds\")\n",
    "                agent.performance -= 5\n",
    "                '''This module handles the case when the agent decided to move down. It follows the same logic as the previous module'''\n",
    "                \n",
    "        elif action == \"Greuse\":\n",
    "            items = self.list_things_at(agent.location, tclass=ReuseTool)\n",
    "            if len(items) != 0:\n",
    "                if agent.greuse(items[0]):\n",
    "                    self.delete_thing(items[0])\n",
    "                    self.matrix[items[0].location[0]][items[0].location[1]] = '-'\n",
    "                    agent.memories.remove(items[0])\n",
    "                    '''This module handles the case when the agent decides to grab a reusable tool. First a confirmation that a reusable tool object is\n",
    "                    indeed in the current agent's location is performed. Upon success in the check, the agent picks up the tool, then it is deleted from\n",
    "                    the env (internally from the array of things in the env) and finally the graphic representation of the env is modified accordingly. \n",
    "                    The tool existence in the agent's memory is also erased'''\n",
    "        \n",
    "        elif action == \"Gdispos\":\n",
    "            agent.gdispos()\n",
    "            items = self.list_things_at(agent.location, tclass=DisposTool)\n",
    "            if len(items) != 0:\n",
    "                if agent.gdispos(items[0]):\n",
    "                    self.delete_thing(items[0])\n",
    "                    self.matrix[items[0].location[0]][items[0].location[1]] = '-'\n",
    "                    agent.memories.remove(items[0])\n",
    "                    '''This module handles the case when the agent decides to grab a disposable tool. It follows the same logic as the previous module'''\n",
    "        \n",
    "        elif action == \"GTreasure1\":\n",
    "            items = self.list_things_at(agent.location, tclass=Treasure1)\n",
    "            if len(items) != 0:\n",
    "                if agent.gTreasure1(items[0]): \n",
    "                    self.delete_thing(items[0])\n",
    "                    self.matrix[items[0].location[0]][items[0].location[1]] = '-'\n",
    "                    agent.memories.remove(items[0])\n",
    "                    '''This module handles the case when the agent decides to grab a type 1 treasure. It follows the same logic as the previous module'''\n",
    "        \n",
    "        elif action == \"GTreasure2\":\n",
    "            items = self.list_things_at(agent.location, tclass=Treasure2)\n",
    "            if len(items) != 0:\n",
    "                if agent.gTreasure2(items[0]):\n",
    "                    self.delete_thing(items[0])\n",
    "                    self.matrix[items[0].location[0]][items[0].location[1]] = '-'\n",
    "                    agent.memories.remove(items[0])\n",
    "                    '''This module handles the case when the agent decides to grab a type 2 treasure. It follows the same logic as the previous module'''\n",
    "        \n",
    "        elif action == \"NoOp\":\n",
    "            pass\n",
    "        \n",
    "        #Report the modified environment along with agent status\n",
    "        print(\"NEW AGENT'S PERFORMANCE: \" + str(agent.performance))\n",
    "        print(\"NEW ENVIRONMENT STATE\")\n",
    "        print(\"Agent location: \" + str(agent.location))\n",
    "        print(\"Agent tools: \" + str(agent.holding))\n",
    "        print('\\n'.join([''.join(['{:3}'.format(item) for item in row]) \n",
    "              for row in self.matrix]))\n",
    "    \n",
    "    def run(self, steps=50): #AIMA function overriden to create a graphical representation of the environment and report starting status\n",
    "        \"Run the Environment for given number of time steps.\"\n",
    "        print(\"MODEL-BASED REFLEX AGENT in PARTIALLY OBSERVABLE ENVIRONMENT\")\n",
    "        print(\"<STARTING>\")\n",
    "        print(\"Agent location: \" + str(self.things[0].location))\n",
    "        print(\"Agent tools: \" + str(self.things[0].holding))\n",
    "        \n",
    "        self.matrix = templateEnv(size = 6) #create an empty matrix for representing the environment graphically\n",
    "        self.matrix = fillEnv(self.matrix, self.things) #fill the matrix with objects in the environment\n",
    "        print(\"Agent performance: \" + str(self.things[0].performance))\n",
    "        \n",
    "        for step in range(steps):\n",
    "            if self.is_done():\n",
    "                print(\"\\nFINAL AGENT's PERFORMANCE: \" + str(self.things[0].performance)) #print the performance after last step of the run\n",
    "                return\n",
    "            print(\"\\n<STEP\" + str(step + 1) + \">\") #print step number starting from 1\n",
    "            self.step()\n",
    "        \n",
    "        print(\"\\nFINAL AGENT's PERFORMANCE: \" + str(self.things[0].performance)) #print the performance after last step of the run\n",
    "        \n",
    "    def step(self): #AIMA function overriden to access agent status in each step of a run and print the performance\n",
    "        \"\"\"Run the environment for one time step. If the\n",
    "        actions and exogenous changes are independent, this method will\n",
    "        do.  If there are interactions between them, you'll need to\n",
    "        override this method.\"\"\"\n",
    "        if not self.is_done():\n",
    "            actions = []\n",
    "            for agent in self.agents:\n",
    "                if agent.alive:\n",
    "                    actions.append(agent.program(agent, self.percept(agent)))\n",
    "                else:\n",
    "                    actions.append(\"\")\n",
    "                \n",
    "            #Print a graphical matrix representation of what the agent was percieving along with its status at that moment\n",
    "            print(\"PERCEPT\")\n",
    "            print(\"Agent location: \" + str(agent.location))\n",
    "            print(\"Agent tools: \" + str(agent.holding))\n",
    "            percept_repr = templateEnv(size = 6)\n",
    "            getUnknownsModel(percept_repr, agent.location, agent.memories)\n",
    "                \n",
    "            for (agent, action) in zip(self.agents, actions):\n",
    "                self.execute_action(agent, action)\n",
    "            self.exogenous_change()\n",
    "            \n",
    "    def is_done(self): #AIMA function overriden to terminate the run if there are no objects of interest left in the environment\n",
    "        no_edibles = not any(isinstance(thing, Treasure1) or isinstance(thing, DisposTool) or isinstance(thing, ReuseTool) or isinstance(thing, Treasure2) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n",
    "    \n",
    "    \n",
    "#Create a simple reflex agent for use in an island environment\n",
    "class ModelHunter(Agent):\n",
    "    def __init__(self, program=None): #default state of the agent\n",
    "        self.alive = True\n",
    "        self.bump = False\n",
    "        self.holding = []\n",
    "        self.performance = 50\n",
    "        self.memories = [] #this is exclusive to the model-based agent, stores useful percepts it has seen in previous steps of a run\n",
    "        if program is None:\n",
    "            def program(percept):\n",
    "                return eval(input('Percept={}; action? ' .format(percept)))\n",
    "        assert isinstance(program, collections.Callable)\n",
    "        self.program = program\n",
    "        \n",
    "    def remember(self, percepts):\n",
    "        '''This function is called from the program of the agent, first check if there is something on the agent's memory. If its the first step of the\n",
    "        run this will be true and the whole current percept is appended to the memory. If its not the first step of the run then the agent needs to\n",
    "        check if the current percept contain useful information that he previously didn't know. New useful percepts are appended to the memory.'''\n",
    "        if len(self.memories) == 0:\n",
    "            self.memories = percepts\n",
    "        else:\n",
    "            temp = percepts\n",
    "            for thing in self.memories:\n",
    "                for p in percepts:\n",
    "                    if p is thing:\n",
    "                        temp.remove(p)\n",
    "                    else:\n",
    "                        pass\n",
    "            if len(temp) > 0:\n",
    "                for p in temp:\n",
    "                    self.memories.append(p)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "    #The following 4 methods are actions that the agent executes when it wants to move. Which move of the four is called depends on the calculations\n",
    "    #made in the reflexProgram() function and on wether or not the action is valid in the current state of the environment as seen in execute_action()\n",
    "    #in the environment's methods. Performance is reduced by one point in all cases\n",
    "    def moveRight(self):\n",
    "        self.performance -= 1\n",
    "        self.location[1] += 1\n",
    "\n",
    "    def moveLeft(self):\n",
    "        self.performance -= 1\n",
    "        self.location[1] -= 1\n",
    "\n",
    "    def moveUp(self):\n",
    "        self.performance -= 1\n",
    "        self.location[0] -= 1\n",
    "\n",
    "    def moveDown(self):\n",
    "        self.performance -= 1\n",
    "        self.location[0] += 1\n",
    "\n",
    "    #The following 4 functions are actions that the agent executes when it wants to grab something. They operate in the a similar fashion as the\n",
    "    #movement methods except that the agent's inventory is also manipulated\n",
    "    def greuse(self, thing):\n",
    "        self.performance -= 1\n",
    "        if isinstance(thing, ReuseTool):\n",
    "            print(\"SELECTED ACTION: Greuse\")\n",
    "            self.holding.append('H')\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def gdispos(self, thing = None):\n",
    "        self.performance -= 1\n",
    "        if isinstance(thing, DisposTool):\n",
    "            print(\"SELECTED ACTION: Gdispos\")\n",
    "            self.holding.append('h')\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def gTreasure1(self, thing):\n",
    "        if isinstance(thing, Treasure1):\n",
    "            print(\"SELECTED ACTION: GTreas1\")\n",
    "            self.performance += 20\n",
    "            if 'H' in self.holding == False:\n",
    "                self.holding.remove('h')\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def gTreasure2(self, thing):\n",
    "        if isinstance(thing, Treasure2):\n",
    "            print(\"SELECTED ACTION: GTreas2\")\n",
    "            self.performance += 40\n",
    "            self.holding.remove('h')\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    #This action is performed when there is a wall at a cell where the agent wants to move to. Mantains the agent's location for the current step\n",
    "    def NoOp(self):\n",
    "        print(\"SELECTED ACTION: NoOp saw a wall\")\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def modelProgram(agent, percepts):\n",
    "    '''returns a string dictating the action to be performed by the agent and ultimately what needs to be modified in environment'''\n",
    "    agent.remember(percepts) #call this method to append useful current percepts to the agent's memory\n",
    "    \n",
    "    actionTaken = False\n",
    "    \n",
    "    for p in agent.memories: #works with the whole agent's memory and not just the current percept\n",
    "        if actionTaken:\n",
    "            break\n",
    "            \n",
    "        in_location = agent.location == p.location #used to check the agent's current location for a grabable object\n",
    "        \n",
    "        if isinstance(p, Treasure1) and ('h' in agent.holding or 'H' in agent.holding):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'GTreasure1'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "                '''This module handles when the agent is able to sense a type 1 treasure. First check if the agent has a any kind of tool to grab the\n",
    "                treasure: if not then let this iteration of the loop pass because there is no way to obtain the treasure right now (a new percept is\n",
    "                checked in the next iteration), if yes check if the treasure is at the same place as the agent, if not move towards it by calling the\n",
    "                getDirection() function, if yes output the grab action'''\n",
    "        \n",
    "        elif isinstance(p, Treasure2) and 'h' in agent.holding:\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'GTreasure2'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "                '''This module handles when the agent is able to sense a type 2 treasure. It works in the same fashion as the last module with the\n",
    "                difference being that only disposable tools on inventory are considered in the first condition check and not any kind of tool as in\n",
    "                the previous module'''\n",
    "            \n",
    "        elif isinstance(p, DisposTool):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'Gdispos'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "                '''This module handles when the agent is able to sense a disposable tool. I simply checks if the tool is in the current location of the\n",
    "                agent to pick it up or otherwise move towards it calling the getDirection() function'''\n",
    "            \n",
    "        elif isinstance(p, ReuseTool):\n",
    "            if in_location:\n",
    "                actionTaken = True\n",
    "                return 'Greuse'\n",
    "            else:\n",
    "                moveTo = getDirection(agent.location, p.location)\n",
    "                actionTaken = True\n",
    "                return moveTo\n",
    "                '''This module handles when the agent is able to sense a reusable tool. Works the same as the last module'''\n",
    "    \n",
    "    if not actionTaken:\n",
    "        return 'moveRandom'\n",
    "    \n",
    "def getDirection(origin, goal):\n",
    "    '''Decides an action that will move the agent one cell closer (in manhatan distance) to an object it wants to pick up'''\n",
    "    if origin[1] < goal[1]:\n",
    "        return 'moveRight'\n",
    "    elif origin[1] > goal[1]:\n",
    "        return 'moveLeft'\n",
    "    elif origin [0] > goal[0]:\n",
    "        return 'moveUp'\n",
    "    else:\n",
    "        return 'moveDown'\n",
    "    \n",
    "def templateEnv(size):\n",
    "    '''Creates an empty matrix to represent an enviroment or agent's percept'''\n",
    "    matrix = np.array([['-' for i in range (0, size + 2)] for j in range (0, size + 2)])\n",
    "    \n",
    "    #Make the matrix pretty with outer rol and col aesthetics\n",
    "    for i in range(0, size + 2):\n",
    "        for j in range(0, size + 2):\n",
    "            if (i == 0 and j == 0) or (i == size + 1 and j == size + 1):\n",
    "                matrix[i][j] = '\\\\'\n",
    "\n",
    "            elif (i == 0 and j == size + 1) or (i == size + 1 and j == 0):\n",
    "                matrix[i][j] = '/'\n",
    "\n",
    "            elif i == 0 and (j != 0 or j!= size + 1):\n",
    "                matrix[i][j] = str(j)\n",
    "            \n",
    "            elif i == size + 1 and (j != 0 or j!= size + 1):\n",
    "                matrix[i][j] = str(j)\n",
    "\n",
    "            elif (i != 0 or i != size + 1) and j == 0:\n",
    "                matrix[i][j] = str(i)\n",
    "            \n",
    "            elif (i != 0 or i != size + 1) and j == size + 1:\n",
    "                matrix[i][j] = str(i)\n",
    "    return matrix\n",
    "\n",
    "def fillEnv(matrix, things):\n",
    "    '''fills an empty matrix with objects in the environment at their proper locations'''\n",
    "    \n",
    "    for thing in things:\n",
    "        if isinstance(thing, Treasure1):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 'T'\n",
    "        elif isinstance(thing, Treasure2):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 't'\n",
    "        elif isinstance(thing, DisposTool):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 'h'\n",
    "        elif isinstance(thing, ReuseTool):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 'H'\n",
    "        elif isinstance(thing, Wall):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 'X'\n",
    "        \n",
    "    print('\\n'.join([''.join(['{:3}'.format(item) for item in row]) \n",
    "           for row in matrix]))\n",
    "    return matrix\n",
    "    \n",
    "def getUnknownsModel(matrix, reference, memories):\n",
    "    '''modifies the graphical representation of the agent's percept to reflect the cells it can't sense and the cells it has seen\n",
    "    in previous steps that contain relevant objects (for partial env)'''\n",
    "    for thing in memories:\n",
    "        if isinstance(thing, Treasure1):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 'T'\n",
    "        elif isinstance(thing, Treasure2):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 't'\n",
    "        elif isinstance(thing, DisposTool):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 'h'\n",
    "        elif isinstance(thing, ReuseTool):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 'H'\n",
    "        elif isinstance(thing, Wall):\n",
    "            matrix[thing.location[0]][thing.location[1]] = 'X'\n",
    "    \n",
    "    for i in range(1, len(matrix) - 1):\n",
    "            for j in range(1, len(matrix) - 1):\n",
    "                \n",
    "                if matrix[i, j] == '-':\n",
    "                    if [i, j] != reference:\n",
    "                        if [i+1, j] != reference and [i-1, j] != reference:\n",
    "                            if [i, j+1] != reference and [i, j-1] != reference:\n",
    "                                if [i+1, j+1] != reference and [i-1, j-1] != reference:\n",
    "                                    if [i+1, j-1] != reference and [i-1, j+1] != reference:\n",
    "                                        matrix[i][j] = '?'\n",
    "                                        \n",
    "    print('\\n'.join([''.join(['{:3}'.format(item) for item in row]) \n",
    "          for row in matrix]))\n",
    "\n",
    "def main(start=[1, 1]):\n",
    "    '''Run the model-based reflex hunter in the partial treasure island environment'''\n",
    "    partial_island = PartialIsland()\n",
    "    mike = ModelHunter(modelProgram)\n",
    "\n",
    "    #Create 3 objects of each kind to place on the environment\n",
    "    treasure1A = Treasure1()\n",
    "    treasure1B = Treasure1()\n",
    "    treasure1C = Treasure1()\n",
    "    treasure2A = Treasure2()\n",
    "    treasure2B = Treasure2()\n",
    "    treasure2C = Treasure2()\n",
    "    dispos1 = DisposTool()\n",
    "    dispos2 = DisposTool()\n",
    "    dispos3 = DisposTool()\n",
    "    reusable1 = ReuseTool()\n",
    "    reusable2 = ReuseTool()\n",
    "    reusable3 = ReuseTool()\n",
    "    wall = Wall()\n",
    "    wall2 = Wall()\n",
    "    wall3 = Wall()\n",
    "\n",
    "    partial_island.add_thing(mike, start)\n",
    "    mike.performance = 50 #prevents AIMA from resetting the performance to 0 when adding the agent to the environment\n",
    "    \n",
    "    #add things randomly preventing placing more than one item in a single cell in the environment\n",
    "    xy = [[1, 1],[1, 2],[1, 3],[1, 4],[1, 5],[1, 6],\n",
    "          [2, 1],[2, 2],[2, 3],[2, 4],[2, 5],[2, 6],\n",
    "          [3, 1],[3, 2],[3, 3],[3, 4],[3, 5],[3, 6],\n",
    "          [4, 1],[4, 2],[4, 3],[4, 4],[4, 5],[4, 6],\n",
    "          [5, 1],[5, 2],[5, 3],[5, 4],[5, 5],[5, 6],\n",
    "          [6, 1],[6, 2],[6, 3],[6, 4],[6, 5],[6, 6]]\n",
    "\n",
    "    partial_island.add_thing(treasure1A, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(treasure1B, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(treasure1C, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(reusable1, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(reusable2, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(reusable3, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(treasure2A, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(treasure2B, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(treasure2C, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(dispos1, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(dispos2, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(dispos3, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(wall, xy.pop(randint(0, len(xy)) - 1))\n",
    "    partial_island.add_thing(wall2, xy.pop(randint(0, len(xy) - 1)))\n",
    "    partial_island.add_thing(wall3, xy.pop(randint(0, len(xy) - 1)))\n",
    "\n",
    "    partial_island.run(50) #run the program for 50 iterations\n",
    "    return mike.performance #for studying several runs\n",
    "                                          \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell executes 500 runs of 50 iterations each of the previous agent and environment. The average agent performance of the runs is computed (takes less than a minute to run but its not inmediate please be patient). The agent location for these runs is also randomized like the location of the objects. Stdout is supressed to avoid excessive printing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "total_performance = 0\n",
    "for i in range (1, 500):\n",
    "    run_result = main(start=[randint(1, 6), randint(1, 6)]);\n",
    "    total_performance += run_result\n",
    "average_performance = total_performance / 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell prints the average agent performance from the last experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.458"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONS #\n",
    "\n",
    "<b> Who behaves better, the simple reflex agent or the model based reflex agent? </b>\n",
    "\n",
    "They perform fairly similar, depending on the type of the environment and the configuration of the thing in it. In the fully observable environment they perform exactly the same way, while on most configurations for the partially observable environment the model-based agent is able to perform much better due to its ability to avoid series of random movement to revisit objects it has already seen at some point. Average performance over 500 random partially observable environments favours the model-based agent consistenly by about 10 points over the simple-reflex agent (85-90 over 75-80).\n",
    "\n",
    "\n",
    "To observate better the performance Simple-Reflex (SR) and Model-Based (MB) on both enviroments Fully-Observable (FO) and Partial-Observable (PO) we calculate an Average Perfomance Measure that consist on 500 runs, the results are prompted in the following table:\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Agent:</b> </td>\n",
    "        <td>SR-FO </td>\n",
    "        <td>SR-PO</td>\n",
    "        <td>MB-FO</td>\n",
    "         <td>MB-PO</td>\n",
    "      \n",
    "\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td><b>Agent´s Average Perfomance measure:</b> </td>\n",
    "       <td>61.782</td>\n",
    "       <td>80.446</td>\n",
    "       <td>66.96</td>\n",
    "       <td>85.458</td>\n",
    "       \n",
    "   </tr>\n",
    "        \n",
    "</table>\n",
    "\n",
    "\n",
    "<b> How do different types of environments affect different types of agents? </b>\n",
    "\n",
    "In a fully observable environment, both agents perform the same. Having every Thing Object in the percepts lists for every iteration makes it redundant to save an internal memory, thus making the model-based agent no different than the simple reflex.\n",
    "\n",
    "However, on the partially-observable environment, the model-based agent is able to perform much better, as every step taken allows it to get to know the island better and remember the location of desirable objects even if it has to come back later for them.\n",
    "\n",
    "The difference on the agent performance resides on what they are able to perceive. Since the simple reflex has no memory, in the partial environment it will be moving mostly at random until it stumbles upon a desirable object.\n",
    "\n",
    "<b> Do you think the agents are behaving rationally? </b>\n",
    "\n",
    "Yes, they are making the best decision on the information that they have. Except when they face walls which we found to be time consuming to be dealt with in an intelligent way. If a desirable object is behind a wall, the agents will be crashing into it everytime until they run out of iterations. The rules for going past a wall were not part of the scope for this assignment. One quick solution which minimizes performance loss would be to call the \"NoOp\" action to avoid losing performance even if the agent doesn't move away from the wall.\n",
    "\n",
    "<b> What did you have to program differently for agents to work in different environments? </b>\n",
    "\n",
    "The main feature we had to program out of the specifications of the assignment to get results in different environments was the option to move random when no action can be taken based on percepts. This way, the agent won't be stuck on the same position if it can't grab a treasure at its current location. Between the environments themselves the percept function was what changed mainly and the inclusion (or not) of an array for storing past percepts was the main difference between agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language": "fsharp",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
