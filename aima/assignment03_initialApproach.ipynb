{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import *\n",
    "from agents import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tpiece(Thing): #Create a movable piece class\n",
    "    pass\n",
    "\n",
    "class Board(Environment): #Create an environment like last assignment\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSA(SimpleProblemSolvingAgentProgram):\n",
    "    def __call__(self, board): #AIMA overrided function because it had some things wrong\n",
    "        self.percept = board.things #percept will just be the list of objects in the board environment\n",
    "        self.state = self.update_state(self.percept)\n",
    "        if not self.seq:\n",
    "            goal = self.formulate_goal(self.state)\n",
    "            problem = self.formulate_problem(self.state, goal)\n",
    "            self.seq.append(self.search(problem))\n",
    "            #This was originally self.seq = blabla in AIMA which obviously gives an error when trying to pop it later wtf AIMA\n",
    "            if not self.seq:\n",
    "                return None\n",
    "        return self.seq.pop(0) #self.seq goes back empty for working the next goal\n",
    "    \n",
    "    def update_state(self, percept): #from board.things it builds a tuple of tuples to represent the initial state of the current step\n",
    "        #Format: (('Identification char', (location)), next object of the percept in the same format)\n",
    "        #Example: ( ('A', (1, 1)), ('T', (5, 2)) ) <- means a state with agent in 1, 1 and movable piece in 5, 2\n",
    "        #Output needs to be tuple because the AIMA graph search function needs hashable data structures to add to the explored set\n",
    "        \n",
    "        state = [] #Easier to build the state as a list\n",
    "        for p in percept:\n",
    "            if isinstance(p, Agent):\n",
    "                state.append(('A', p.location))\n",
    "            elif isinstance(p, Tpiece):\n",
    "                state.append(('T', p.location))\n",
    "        state = tuple(state) #convert the state to tuple\n",
    "        return state\n",
    "\n",
    "    def formulate_goal(self, state): #returns the desired state of the current step\n",
    "        temp = dict(state)\n",
    "        #converting the state temporarily to a dictionary makes it easier to manip the data, example: {'A': (1,1), 'T': (5, 5)}\n",
    "        \n",
    "        if temp['A'][0] == temp['T'][0] and temp['A'][1] == temp['T'][1] - 1: #If the agent is already to the left of the movable piece\n",
    "            temp['A'] = (5, 4)\n",
    "            temp['T'] = (5, 5)\n",
    "            #The desired state would be to finish the job and have the piece be in 5, 5\n",
    "        else: #The agent is not to the left of the piece yet\n",
    "            temp['A'] = (temp['T'][0], temp['T'][1] - 1)\n",
    "            #The desired state is to initially position the agent to the left of the piece\n",
    "\n",
    "        #This next block simply builds a proper tuple formatted state from the edited dictionary\n",
    "        goal = []\n",
    "        for k in temp.items():\n",
    "            goal.append(k)\n",
    "        goal = tuple(goal)\n",
    "        return goal\n",
    "        '''TODO: obviously develop this function so it can formulate proper goals in all boards. Board 1 only requires \"2 goals\"\n",
    "        which is first to approach the piece and then push it, but some boards will require previous goals such as clearing\n",
    "        a path from obstacles'''\n",
    "\n",
    "    def formulate_problem(self, state, goal): #create a problem object with the initial state and goal state for this step\n",
    "        problem = PushnPull(state, goal)\n",
    "        return problem\n",
    "    \n",
    "    def search(self, problem): #Uses some search algorithm included in AIMA to solve the problem\n",
    "        return graph_search(problem, [])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PushnPull(Problem):\n",
    "    def actions(self, state):\n",
    "        \"\"\"Return the actions that can be executed in the given\n",
    "        state. The result would typically be a list, but if there are\n",
    "        many actions, consider yielding them one at a time in an\n",
    "        iterator, rather than building them all at once.\"\"\"\n",
    "        actions = []\n",
    "        temp = dict(state)\n",
    "        #converting the state temporarily to a dictionary makes it easier to manip the data, example: {'A': (1,1), 'T': (5, 5)}\n",
    "        \n",
    "        if temp['A'][0] == temp['T'][0] and temp['A'][1] == temp['T'][1] - 1: #if agent is to the left of the piece\n",
    "            actions.append('pushRight')\n",
    "        \n",
    "        else: #Agent still far from the piece\n",
    "            if temp['A'][1] == 1: #moving left is out of the grid so its illegal \n",
    "                actions.append('moveRight')\n",
    "            elif temp['A'][1] == 6: #moving right is out of the grid so its illegal\n",
    "                actions.append('moveLeft')\n",
    "            else: #any horizontal move action is legal\n",
    "                actions.append('moveRight')\n",
    "                actions.append('moveLeft')\n",
    "            \n",
    "            if temp['A'][0] == 1: #moving up is out of the grid so its illegal\n",
    "                actions.append('moveDown')\n",
    "            elif temp['A'][0] == 6: #moving down is out of the grid so its illegal\n",
    "                actions.append('moveUp')\n",
    "            else: #any vetical move action is legal\n",
    "                actions.append('moveDown')\n",
    "                actions.append('moveUp')\n",
    "            \n",
    "        return actions\n",
    "        '''TODO: obviously implement more actions for the other scenarios and goals that arise in different boards'''\n",
    "    \n",
    "    def result(self, state, action):\n",
    "        \"\"\"Return the state that results from executing the given\n",
    "        action in the given state. The action must be one of\n",
    "        self.actions(state).\"\"\"\n",
    "        temp = dict(state)\n",
    "        #converting the state temporarily to a dictionary makes it easier to manip the data, example: {'A': (1,1), 'T': (5, 5)}\n",
    "        \n",
    "        if action == 'pushRight':\n",
    "            temp['A'] = (temp['A'][0], temp['A'][1] + 1)\n",
    "            temp['T'] = (temp['T'][0], temp['T'][1] + 1)\n",
    "            #The new state has both the piece and the agent one cell to the right\n",
    "            \n",
    "        else:\n",
    "            if action == 'moveRight':\n",
    "                temp['A'] = (temp['A'][0], temp['A'][1] + 1)\n",
    "            elif action == 'moveLeft':\n",
    "                temp['A'] = (temp['A'][0], temp['A'][1] - 1)\n",
    "            elif action == 'moveUp':\n",
    "                temp['A'] = (temp['A'][0] - 1, temp['A'][1])\n",
    "            elif action == 'moveDown':\n",
    "                temp['A'] = (temp['A'][0] + 1, temp['A'][1])\n",
    "            #The new state has the agent move accordingly and the piece position is unchanged\n",
    "        \n",
    "        #This next block simply builds a proper tuple formatted state from the edited dictionary\n",
    "        result = []\n",
    "        for k in temp.items():\n",
    "            result.append(k)\n",
    "        result = tuple(result)\n",
    "        return result\n",
    "        '''TODO: obviously handle the proper state changes that arise from other actions and scenarios not implemented yet in\n",
    "        self.actions()'''\n",
    "    \n",
    "    def goal_test(self, state):\n",
    "        \"\"\"Return True if the state is a goal. The default method compares the\n",
    "        state to self.goal or checks for state in self.goal if it is a\n",
    "        list, as specified in the constructor. Override this method if\n",
    "        checking against a single self.goal is not enough.\"\"\"\n",
    "        if state == self.goal:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_search(problem, frontier): #This is just a default AIMA search algorithm which is ran from an agent's search method\n",
    "    \"\"\"Search through the successors of a problem to find a goal.\n",
    "    The argument frontier should be an empty queue.\n",
    "    If two paths reach a state, only use the first one. [Figure 3.7]\"\"\"\n",
    "    frontier.append(Node(problem.initial))\n",
    "    explored = set()\n",
    "    while frontier:\n",
    "        node = frontier.pop()\n",
    "        if problem.goal_test(node.state):\n",
    "            return node\n",
    "        explored.add(node.state)\n",
    "        frontier.extend(child for child in node.expand(problem)\n",
    "                        if child.state not in explored and\n",
    "                        child not in frontier)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence of states to get to the left side of the movable piece:\n",
      "[<Node (('A', (1, 1)), ('T', (5, 2)))>, <Node (('A', (2, 1)), ('T', (5, 2)))>, <Node (('A', (3, 1)), ('T', (5, 2)))>, <Node (('A', (4, 1)), ('T', (5, 2)))>, <Node (('A', (5, 1)), ('T', (5, 2)))>]\n",
      "\n",
      "Sequence of actions to get to the left side of the movable piece:\n",
      "['moveDown', 'moveDown', 'moveDown', 'moveDown']\n",
      "\n",
      "Sequence of states to push the movable piece to the target\n",
      "[<Node (('A', (5, 1)), ('T', (5, 2)))>, <Node (('A', (5, 2)), ('T', (5, 3)))>, <Node (('A', (5, 3)), ('T', (5, 4)))>, <Node (('A', (5, 4)), ('T', (5, 5)))>]\n",
      "\n",
      "Sequence of actions to push the movable piece to the target\n",
      "['pushRight', 'pushRight', 'pushRight']\n",
      "\n",
      "Board 1 solved!\n"
     ]
    }
   ],
   "source": [
    "#This is the process for using the code above and solving board 1 of the assignment\n",
    "\n",
    "#Create an empty board, a movable piece and an agent\n",
    "board1 = Board()\n",
    "t1 = Tpiece()\n",
    "mike = PSA()\n",
    "\n",
    "#Add things to the board/env as specified for board1 in the assignment\n",
    "board1.add_thing(mike, (1, 1))\n",
    "board1.add_thing(t1, (5, 2))\n",
    "\n",
    "#Reach the first goal state (agent wants to go near the piece to move it) and save the resulting node class object to a variable\n",
    "first_goal = mike(board1) #This executes the __call__ method of the agent which is where the whole process starts\n",
    "\n",
    "print(\"Sequence of states to get to the left side of the movable piece:\")\n",
    "print(str(first_goal.path()) + \"\\n\") #each node has stored the sequence of nodes used to get to that node\n",
    "print(\"Sequence of actions to get to the left side of the movable piece:\")\n",
    "print(str(first_goal.solution()) + \"\\n\") #each node has stored the sequence of actions to get to that node\n",
    "\n",
    "#Now we need to achieve the second goal which is to push the piece to the target\n",
    "#First lets update the environment/board (this could be done from a fucntion inside the agent or somewhere else, putting it here provisionally)\n",
    "board1.things = [] #clean the old version of the env\n",
    "temp = dict(first_goal.path()[len(first_goal.path()) - 1].state) #get the last state reached (the previous goal state)\n",
    "for k in temp.items(): #Use the previous goal state to update the env/board\n",
    "    if k[0] == 'A':\n",
    "        board1.add_thing(mike, k[1]) #agent is now in 5, 1 to the left of the piece\n",
    "    elif k[0] == 'T':\n",
    "        board1.add_thing(t1, k[1]) #piece actually hasn't moved yet from 5, 2 but its checked again regardless\n",
    "#TODO: graphical representation of the old board and the new one after each step (after each goal state is reached)\n",
    "\n",
    "#Reach the second goal state (piece is in target and agent is 1 cell to the left of target) and save the node class object to a variable\n",
    "second_goal = mike(board1)\n",
    "\n",
    "print(\"Sequence of states to push the movable piece to the target\")\n",
    "print(str(second_goal.path()) + \"\\n\")\n",
    "print(\"Sequence of actions to push the movable piece to the target\")\n",
    "print(str(second_goal.solution()) + \"\\n\")\n",
    "\n",
    "print(\"Board 1 solved!\")\n",
    "#Obviously with more complex boards, more steps will be needed (more \"subgoals\"), here there were only 2 subgoals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language": "fsharp",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
